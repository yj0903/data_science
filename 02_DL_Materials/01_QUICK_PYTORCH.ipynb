{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27068c19",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block\" style=\"border: 2px solid #1976D2;background-color:#E3F2FD;padding:5px;font-size:0.9em;\">\n",
    "본 자료는 저작권법 제25조 2항에 의해 보호를 받습니다. 본 자료를 외부에 공개하지 말아주세요.<br>\n",
    "<b><a href=\"https://school.fun-coding.org/\">잔재미코딩 (https://school.fun-coding.org/)</a> 에서 본 강의를 포함하는 최적화된 로드맵도 확인하실 수 있습니다</b></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2451041d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block\" style=\"border: 2px solid #1976D2;background-color:#E3F2FD;padding:5px;font-size:0.9em;\">\n",
    "제 유투브 채널로 본 강의를 포함한 데이터 전과정 로드맵과 관련 커리어를 이해할 수 있는 영상도 참고로 확인해보시면<br> \n",
    "학습하시는데 큰 그림을 이해하실 수 있으실꺼예요. (괜찮으시면 구독과 좋아요도 부탁드립니다. ㅎ)<br>\n",
    "<b>- 데이터, AI 커리어와 데이터 전과정 학습 방법 완벽 가이드: <a href=\"https://youtu.be/vsoAyh4D-zw\">https://youtu.be/vsoAyh4D-zw</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b731c7",
   "metadata": {},
   "source": [
    "## PyTorch\n",
    "- numpy가 지원하는 연산들을 GPU에서 할 수 있도록 함\n",
    "- 높은 유연성과 성능을 제공하는 딥러닝 지원\n",
    "\n",
    "> 따라서, numpy 와 유사한 측면이 많음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028613bd",
   "metadata": {},
   "source": [
    "### pytorch 의 일반적인 import 형태"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0066347e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dde4f53",
   "metadata": {},
   "source": [
    "### Tensor 생성\n",
    "- Tensor 는 numpy 의 ndarray 와 상당히 유사한 구조를 지님"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9267d195",
   "metadata": {},
   "source": [
    "### scala (0D 텐서)\n",
    "- scala 는 numpy 로 만들 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b82de059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 0 ()\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "data1 = np.array(10)\n",
    "print (data1, data1.ndim, data1.shape) # ndim 은 axis 축, shape 은 행렬의 차원을 의미함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8e99b6",
   "metadata": {},
   "source": [
    "### vector (1D 텐서)\n",
    "- vector 부터는 pytorch 의 tensor 로 만들 수 있음\n",
    "- shape 은 torch.Size([3]) 와 같이 표현됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "edcca74d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2.]) 1 torch.Size([2]) torch.Size([2])\n",
      "tensor([ 0.0000e+00, -8.5899e+09,  5.1437e-25]) 1 torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "data1 = torch.FloatTensor([1, 2]) # 1, 2 원소를 가진 1D 텐서 선언\n",
    "print (data1, data1.dim(), data1.shape, data1.size()) # dim() 은 축, shape 은 행렬의 차원을 의미함\n",
    "\n",
    "data2 = torch.FloatTensor(3) # 임의의 3개의 원소를 가진 1D 텐서 선언\n",
    "print (data2, data2.dim(), data2.shape) # dim() 은 축, shape 은 행렬의 차원을 의미함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fda7cfff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3.2851e-13, 4.5748e-41],\n",
      "        [9.0147e-19, 4.5748e-41],\n",
      "        [8.8168e-19, 4.5748e-41]]) 2 torch.Size([3, 2])\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.],\n",
      "        [5., 6.]]) 2 torch.Size([3, 2])\n"
     ]
    }
   ],
   "source": [
    "# matrix (2D 텐서)\n",
    "data3 = torch.FloatTensor(3, 2) # shape 을 기반으로 임의의 원소값을 가진 텐서 선언\n",
    "print (data3, data3.dim(), data3.shape) # dim() 은 축, shape 은 행렬의 차원을 의미함\n",
    "\n",
    "data4 = torch.FloatTensor([ [1, 2], [3, 4], [5, 6] ]) # 텐서 구조와 원소값을 파이썬 리스트 기반으로 넣어서, 해당 텐서 선언\n",
    "print (data4, data4.dim(), data4.shape) # dim() 은 축, shape 은 행렬의 차원을 의미함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa592738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1.],\n",
      "         [2.]],\n",
      "\n",
      "        [[3.],\n",
      "         [4.]],\n",
      "\n",
      "        [[5.],\n",
      "         [6.]]]) 3 torch.Size([3, 2, 1])\n",
      "tensor([[[1.],\n",
      "         [2.]],\n",
      "\n",
      "        [[3.],\n",
      "         [4.]],\n",
      "\n",
      "        [[5.],\n",
      "         [6.]]]) 3 torch.Size([3, 2, 1])\n"
     ]
    }
   ],
   "source": [
    "# 3D 텐서\n",
    "data5 = torch.FloatTensor(3, 2, 1) # shape 을 기반으로 임의의 원소값을 가진 텐서 선언\n",
    "print (data5, data5.dim(), data5.shape) # dim() 은 축, shape 은 행렬의 차원을 의미함\n",
    "\n",
    "data6 = torch.FloatTensor([ [ [1], [2] ], [ [3], [4] ], [ [5], [6] ] ]) # 밖에서부터 안쪽으로 3개, 2개, 1개 원소값으로 선언\n",
    "print (data6, data6.dim(), data6.shape) # dim() 은 축, shape 은 행렬의 차원을 의미함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8393a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.],\n",
      "        [2.],\n",
      "        [3.]]) 2 torch.Size([3, 1])\n",
      "tensor([[1., 2., 3.]]) 2 torch.Size([1, 3])\n"
     ]
    }
   ],
   "source": [
    "# 밖에서부터 안쪽으로 텐서 선언 이해\n",
    "data7 = torch.FloatTensor([ [1], [2], [3] ])\n",
    "print (data7, data7.dim(), data7.shape) # dim() 은 축, shape 은 행렬의 차원을 의미함\n",
    "\n",
    "data8 = torch.FloatTensor([ [1, 2, 3] ])\n",
    "print (data8, data8.dim(), data8.shape) # dim() 은 축, shape 은 행렬의 차원을 의미함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbcbfb3",
   "metadata": {},
   "source": [
    "### Tensor 생성 주요 메서드\n",
    "- torch.zeros(x, y, z): 0 값으로 shape 모양의 텐서 생성\n",
    "- torch.ones(x, y, z): 1 값으로 shape 모양의 텐서 생성\n",
    "- torch.rand(x, y, z): 0 부터 1 사이에 균일한 확률 분포로 랜덤한 값을 가진 (x, y) shape 의 텐서 생성\n",
    "- torch.randn(x, y, z): 기댓값이 0이고, 표준편차가 1인 가우시안 표준 정규 분포를 따르는 랜덤값을 가진 (x, y) shape 의 텐서 생성\n",
    "- torch.full((x, y, z), a): a 값으로, shape 모양의 텐서 생성\n",
    "<br><br>\n",
    "- torch.zeros_like(tensor): 인자로 들어간 tensor 객체와 동일 shape 를 가지되, 각 원소값은 0 으로 이루어진 텐서 생성\n",
    "- torch.ones_like(tensor): 인자로 들어간 tensor 객체와 동일 shape 를 가지되, 각 원소값은 0 으로 이루어진 텐서 생성\n",
    "- torch.rand_like(tensor): 0 부터 1 사이에 균일한 확률 분포로 랜덤한 값을 가진 (x, y) shape 의 텐서 생성\n",
    "- torch.randn_like(tensor): 인자로 들어간 tensor 객체와 동일 shape 를 가지되, 각 원소값은 randn() 의 랜덤값으로 채워진 텐서 생성\n",
    "- torch.full_like(tensor, a): 인자로 들어간 tensor 객체와 동일 shape 를 가지되, 각 원소값은 a 값으로 이루어진 텐서 생성\n",
    "<br><br>\n",
    "- torch.empty(x, y, z): 특정 의도로 초기화 되지 않은 값을 가진 (x, y) shape 의 행렬 생성\n",
    "\n",
    "> shape 은 여러 차원이 될 수 있음 \n",
    "> 각 메서드에 dtype=type 인자를 넣어, 데이터 타입 명시 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180dc448",
   "metadata": {},
   "source": [
    "#### Tensor 데이터 타입\n",
    "\n",
    "<img src=\"https://www.fun-coding.org/00_Images/pytorch-type.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f02844f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "data1 = torch.zeros(2, dtype=torch.float)\n",
    "data2 = torch.ones(2, 2, dtype=torch.double)\n",
    "data3 = torch.rand(2, 2, 3, dtype=torch.half)\n",
    "data4 = torch.randn(2, 2, 3, 4)\n",
    "data5 = torch.full((2,4), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0e64088d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2]) torch.Size([2, 2]) torch.Size([2, 2, 3]) torch.Size([2, 2, 3, 4]) torch.Size([2, 4])\n"
     ]
    }
   ],
   "source": [
    "# 형태 확인\n",
    "print (data1.shape, data2.shape, data3.shape, data4.shape, data5.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "01385f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3 4 2\n",
      "1 2 3 4 2\n"
     ]
    }
   ],
   "source": [
    "# 배열의 차원을 나타냄\n",
    "print (data1.ndim, data2.ndim, data3.ndim, data4.ndim, data5.ndim)\n",
    "print (data1.dim(), data2.dim(), data3.dim(), data4.dim(), data5.dim()) # dim() 메서드로도 차원값을 확인 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f8a56e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32 torch.float64 torch.float16 torch.float32 torch.int64\n"
     ]
    }
   ],
   "source": [
    "# 데이터 타입 확인\n",
    "print (data1.dtype, data2.dtype, data3.dtype, data4.dtype, data5.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "880ed27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2]) torch.Size([2, 2]) torch.Size([2, 2, 3]) torch.Size([2, 2, 3, 4]) torch.Size([2, 4])\n"
     ]
    }
   ],
   "source": [
    "# 데이터 사이즈(원소 갯수) 확인\n",
    "# numpy 와 달리 size 가 아닌 size() 메서드로 제공\n",
    "print (data1.size(), data2.size(), data3.size(), data4.size(), data5.size()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1dc15dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 원소값을 직접 대입하여 tensor 선언\n",
    "data6 = torch.FloatTensor([ [1, 2], [3, 4] ])\n",
    "data7 = torch.DoubleTensor([ [1, 2, 3], [4, 5, 6] ])\n",
    "data8 = torch.LongTensor([ [1, 2, 3], [4, 5, 6], [7, 8, 9] ])\n",
    "\n",
    "# shape 을 기반으로 tensor 선언\n",
    "data9 = torch.FloatTensor(2, 3, 5)\n",
    "data10 = torch.DoubleTensor(3, 3, 2, 4)\n",
    "data11 = torch.LongTensor(4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a69ad3c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[140218417020940, 140218359487024, 140218417083200, 140218359486736],\n",
       "        [140218359486736, 140218359486768, 140218417082432, 140218359487056],\n",
       "        [140218417082240, 140218359677072, 140218417083200, 140218359486736],\n",
       "        [140218359486736, 140218359486768, 140218417082432, 140218359487120]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6869574a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _like() 로 tensor 생성\n",
    "data12 = torch.full_like(data5, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1464accc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[10, 10, 10, 10],\n",
      "        [10, 10, 10, 10]])\n",
      "tensor([[20, 20, 20, 20],\n",
      "        [20, 20, 20, 20]])\n"
     ]
    }
   ],
   "source": [
    "print (data5)\n",
    "print (data12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95965e39",
   "metadata": {},
   "source": [
    "### reshape() : 배열 구조 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "73819f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]], dtype=torch.float64) torch.Size([2, 3])\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.],\n",
      "        [5., 6.]], dtype=torch.float64) torch.Size([3, 2])\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]], dtype=torch.float64) torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "data1 = torch.DoubleTensor([ [1, 2, 3], [4, 5, 6] ])\n",
    "print (data1, data1.shape)\n",
    "data1 = data1.reshape(3, 2)\n",
    "print (data1, data1.shape)\n",
    "data1 = data1.reshape(2, -1) # -1 은 열을 행의 갯수에 맞춰 자동 계산\n",
    "print (data1, data1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0a5d78",
   "metadata": {},
   "source": [
    "### view() : 텐서 구조 변경\n",
    "- pytorch 에서는 numpy 처럼 reshape() 로 배열 구조를 변경할 수 있지만, reshape() 보다 view() 메서드를 보다 많이 사용함\n",
    "- view() 메서드는 reshape() 와 사용법은 동일\n",
    "\n",
    "> 원소 수를 유지하면서 텐서의 크기 변경할 때 많이 사용하며, 매우 중요함!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe1defc",
   "metadata": {},
   "source": [
    "> 상당히 헷깔리므로, 높이, 너비, 깊이 순서로 순서를 기억하는 편이 좋음\n",
    "\n",
    "<img src=\"https://www.fun-coding.org/00_Images/tensor-R.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e0bc45cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 3]) 높이(k): 2 너비(n): 2 깊이(m): 3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "data1 = torch.DoubleTensor([ \n",
    "    [[1, 2, 3], \n",
    "    [4, 5, 6]],\n",
    "    [[7, 8, 9], \n",
    "    [10, 11, 12]]\n",
    "])\n",
    "print (data1.shape, \"높이(k):\", data1.size(0), \"너비(n):\", data1.size(1), \"깊이(m):\", data1.size(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2a4c7f40",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  2.,  3.,  4.,  5.,  6.],\n",
      "        [ 7.,  8.,  9., 10., 11., 12.]], dtype=torch.float64) torch.Size([2, 6])\n",
      "tensor([[ 1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.],\n",
      "        [ 7.,  8.,  9.],\n",
      "        [10., 11., 12.]], dtype=torch.float64) torch.Size([4, 3])\n",
      "tensor([[[ 1.,  2.],\n",
      "         [ 3.,  4.]],\n",
      "\n",
      "        [[ 5.,  6.],\n",
      "         [ 7.,  8.]],\n",
      "\n",
      "        [[ 9., 10.],\n",
      "         [11., 12.]]], dtype=torch.float64) torch.Size([3, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "data1 = data1.view(2, -1) # (2, ?) 으로 구성, -1 은 자동 계산, (2, 2x3) 이 됨  \n",
    "print (data1, data1.shape)\n",
    "\n",
    "data1 = data1.view(-1, 3) # (?, 3) 으로 구성, -1 은 자동 계산, (2x2, 3) 이 됨  \n",
    "print (data1, data1.shape)\n",
    "\n",
    "data1 = data1.view(3, 2, -1) # (3, 2, ?) 으로 구성, -1 을 사용하여, 적절히 변형 가능한 형태로 텐서 변경 가능함\n",
    "print (data1, data1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7db10c5",
   "metadata": {},
   "source": [
    "### squeeze() : 텐서 차원 압축\n",
    "- 차원이 1인 경우, 해당 차원을 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b3a77b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.],\n",
      "        [2.],\n",
      "        [3.]]) 2 torch.Size([3, 1])\n",
      "tensor([1., 2., 3.]) 1 torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "data1 = torch.FloatTensor([ [1], [2], [3] ])\n",
    "data2 = data1.squeeze()\n",
    "print (data1, data1.dim(), data1.shape)\n",
    "print (data2, data2.dim(), data2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "26a17b1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 4])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data4 = torch.randn(2, 1, 3, 4)\n",
    "data4.squeeze().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ed8192",
   "metadata": {},
   "source": [
    "### unsqueeze() : 특정 위치에 1인 차원을 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "488262e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]]) 2 torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "data1 = torch.FloatTensor([ [1, 2, 3], [4, 5, 6] ])\n",
    "print (data1, data1.dim(), data1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0c279cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 2., 3.],\n",
      "         [4., 5., 6.]]]) 3 torch.Size([1, 2, 3])\n",
      "tensor([[[1., 2., 3.]],\n",
      "\n",
      "        [[4., 5., 6.]]]) 3 torch.Size([2, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "data2 = data1.unsqueeze(0)\n",
    "data3 = data1.unsqueeze(1)\n",
    "print (data2, data2.dim(), data2.shape)\n",
    "print (data3, data3.dim(), data3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635d6f49",
   "metadata": {},
   "source": [
    "### 데이터 타입 변환 (type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82625ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32 torch.float64 torch.float16\n",
      "torch.float32 torch.int32 torch.float64\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "data1 = torch.zeros(2, dtype=torch.float)\n",
    "data2 = torch.ones(2, 4, dtype=torch.double)\n",
    "data3 = torch.rand(2, 2, 3, dtype=torch.half)\n",
    "print (data1.dtype, data2.dtype, data3.dtype)\n",
    "\n",
    "data1 = data1.type(torch.float32)\n",
    "data2 = data2.type(torch.int)\n",
    "data3 = data3.type(torch.double)\n",
    "print (data1.dtype, data2.dtype, data3.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c15c66c",
   "metadata": {},
   "source": [
    "### T: 전치(transpose) 행렬\n",
    "- 행과 열을 교환하여 얻는 행렬을 의미, $A^T$ 로 표현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2de0131d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1, 1],\n",
      "        [1, 1, 1, 1]], dtype=torch.int32)\n",
      "tensor([[1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "print (data2)\n",
    "data2 = data2.T\n",
    "print (data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872a42bd",
   "metadata": {},
   "source": [
    "### numpy 와 pytorch\n",
    "- PyTorch 는 numpy 의 ndarray 를 GPU 에서 실행시킬 수 있도록 하기 위해 개발되었으므로,\n",
    "- PyTorch 의 tensor 와 numpy 의 ndarray 는 서로 변환 가능\n",
    "- 이를 위해 PyTorch 에서 다음 메서드 제공\n",
    "  - 텐서객체.numpy(): tensor 객체를 numpy 의 ndarray 객체로 변환\n",
    "  - torch.from_numpy(ndarray): numpy 의 ndarray 를 tensor 객체로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0284da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]] <class 'numpy.ndarray'>\n",
      "tensor([[1, 2],\n",
      "        [3, 4]]) <class 'torch.Tensor'>\n",
      "[[1 2]\n",
      " [3 4]] <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "data1 = np.array([ [1, 2], [3, 4] ])\n",
    "print (data1, type(data1))\n",
    "data2 = torch.from_numpy(data1)\n",
    "print (data2, type(data2))\n",
    "data3 = data2.numpy()\n",
    "print (data3, type(data3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acaa27ce",
   "metadata": {},
   "source": [
    "### arange() : 1차원 tensor 생성\n",
    "- torch.arange(start, stop, step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e2b08f05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a21d82e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b45f5a30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 3, 5, 7, 9])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(1, 5, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e99f808",
   "metadata": {},
   "source": [
    "### linspace() : 범위 내 1차원 tensor 균등 생성\n",
    "- torch.linspace(start, stop, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab8b9be7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.4444, 1.8889, 2.3333, 2.7778, 3.2222, 3.6667, 4.1111, 4.5556,\n",
       "        5.0000])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linspace(1, 5, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6489e8cc",
   "metadata": {},
   "source": [
    "### tensor 연산\n",
    "- 본래 행렬 곱셈은 앞 행렬의 열의 갯수와 뒷 행렬의 행의 갯수가 같아야 행렬간 곱셈이 가능하지만,\n",
    "- tensor 연산은 shape 가 동일해야 하고, 행과 열이 같은 값끼리 연산이 됨\n",
    "\n",
    "```python\n",
    "data1 = torch.randn(3, 2)\n",
    "data2 = torch.randn(2, 3)\n",
    "data1 * data2 # shape 이 다르므로 연산이 안됨\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cab0ad2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3, 3, 3],\n",
      "        [3, 3, 3],\n",
      "        [3, 3, 3]])\n",
      "tensor([[1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1]])\n",
      "tensor([[2, 2, 2],\n",
      "        [2, 2, 2],\n",
      "        [2, 2, 2]])\n",
      "tensor([[2., 2., 2.],\n",
      "        [2., 2., 2.],\n",
      "        [2., 2., 2.]])\n"
     ]
    }
   ],
   "source": [
    "data1 = torch.full((3, 3), 2)\n",
    "data2 = torch.full((3, 3), 1)\n",
    "print (data1 + data2)\n",
    "print (data1 - data2)\n",
    "print (data1 * data2)\n",
    "print (data1 / data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7f134aaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4, 4, 4],\n",
       "        [4, 4, 4],\n",
       "        [4, 4, 4]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = torch.full((3, 2), 2)\n",
    "data2 = torch.full((2, 3), 1)\n",
    "torch.matmul(data1, data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a433b890",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[43mdata1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata2\u001b[49m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "print (data1 * data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414dfa93",
   "metadata": {},
   "source": [
    "### Tensor 연산 (브로드캐스팅)\n",
    "- Tensor 간 연산이 broadcasting 을 지원하면, Tensor 는 동일한 차원으로 자동 확장됨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4b4161",
   "metadata": {},
   "source": [
    "### broadcasting 이해\n",
    "- 둘 tensor 중 하나의 차원의 원소 수가 1이거나, 존재하지 않는 경우, broadcasting 이 일어나면, 해당 차원이 확대됨\n",
    "<img src=\"https://www.fun-coding.org/00_Images/broadcasting-rule1.png\" width=600>\n",
    "<img src=\"https://www.fun-coding.org/00_Images/broadcasting-rule1-1.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c396f353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1]) torch.Size([3]) torch.Size([3, 3])\n",
      "tensor([[2., 2., 2.],\n",
      "        [3., 3., 3.],\n",
      "        [4., 4., 4.]])\n"
     ]
    }
   ],
   "source": [
    "# 동일 shape 은 당연히 Tensor 간 연산 가능\n",
    "data1 = torch.FloatTensor([ [1], [2], [3] ])\n",
    "data2 = torch.FloatTensor([1, 1, 1])\n",
    "data3 = data1 + data2 \n",
    "print (data1.shape, data2.shape, data3.shape)\n",
    "print (data3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e557a9",
   "metadata": {},
   "source": [
    "### broadcasting 조건\n",
    "- 두 tensor 간의 브로드캐스팅이 가능하기 위한 조건이 있음\n",
    "  - 두 tensor 에 있는 각 차원에 대해, 끝쪽 차원부터 다음 조건을 비교하며, 앞쪽 방향으로 진행 \n",
    "     - 각 차원의 원소 수가 똑같거나\n",
    "     - 둘 중의 하나의 차원의 원소 수는 1이거나, 존재하지 않는 경우\n",
    "- 주요 브로드캐스팅 가능 케이스를 broadcastable 이라고 함\n",
    "<img src=\"https://www.fun-coding.org/00_Images/numpy-broadcasting.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "43f70b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 20, 4]) torch.Size([20, 4]) torch.Size([10, 20, 4])\n"
     ]
    }
   ],
   "source": [
    "data1 = torch.FloatTensor(10, 20, 4)\n",
    "data2 = torch.FloatTensor(20, 4)\n",
    "data3 = data1 + data2 \n",
    "print (data1.shape, data2.shape, data3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44ba8e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1, 5]) torch.Size([10, 2, 1]) torch.Size([10, 2, 5])\n"
     ]
    }
   ],
   "source": [
    "data1 = torch.FloatTensor(10, 1, 5)\n",
    "data2 = torch.FloatTensor(10, 2, 1)\n",
    "data3 = data1 + data2 \n",
    "print (data1.shape, data2.shape, data3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a830de67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5]) torch.Size([10, 10, 1]) torch.Size([10, 10, 5])\n"
     ]
    }
   ],
   "source": [
    "data1 = torch.FloatTensor(5)\n",
    "data2 = torch.FloatTensor(10, 10, 1)\n",
    "data3 = data1 + data2 \n",
    "print (data1.shape, data2.shape, data3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061406c6",
   "metadata": {},
   "source": [
    "### tensor 의 원소 접근 방법 (indexing)\n",
    "- tensor 의 특정 데이터를 가져오는 기능을 indexing 이라고 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "11467abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "tensor(5.)\n",
      "tensor([2., 5.])\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "tensor([[1., 2.]])\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "data3 = torch.FloatTensor([ [1., 2., 3.], [4., 5., 6.] ])\n",
    "print (data3)\n",
    "print (data3[1, 1]) \n",
    "print (data3[:, 1]) # 슬라이싱, : 는 전체를 의미\n",
    "print (data3[:, :])\n",
    "print (data3[:1, :2]) # 슬라이싱, :1 이란 1 - 1 인 0까지를 의미하므로, 0, 2 - 1 은 1까지를 의미하므로, 0 과 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7ad43d",
   "metadata": {},
   "source": [
    "### boolean indexing\n",
    "- 조건 필터링과 검색을 동시에 할 수 있어서, 유용하게 쓰이는 인덱싱 기법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1d2f6640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[False, False, False],\n",
      "        [ True,  True,  True]])\n",
      "tensor([5., 5., 6.])\n",
      "tensor([5., 5.])\n"
     ]
    }
   ],
   "source": [
    "data1 = torch.FloatTensor([ [1, 2, 3], [5, 5, 6] ])\n",
    "data2 = data1 > 3\n",
    "print (data2)\n",
    "print (data1[data2]) # True 인 값만 추출 가능\n",
    "print (data1[(data1 > 3) & (data1 < 6)]) # 다중 조건으로 &(AND), |(OR) 사용 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da5bab6",
   "metadata": {},
   "source": [
    "### fancy indexing\n",
    "- 다른 배열로 배열을 인덱싱할 수 있는 기능\n",
    "- 이를 통해, 복잡한 배열의 연속되지 않은 일부분을 빠르게 접근할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4aa2c634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0468, -0.0961,  1.3943],\n",
      "        [-1.3831, -1.4610,  0.4911],\n",
      "        [ 0.1361, -0.1071, -0.0923],\n",
      "        [-0.5749,  0.5623,  1.1037]])\n"
     ]
    }
   ],
   "source": [
    "data1 = torch.randn(4, 3)\n",
    "print(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7641f218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.3831, -1.4610,  0.4911],\n",
      "        [ 0.1361, -0.1071, -0.0923]])\n",
      "tensor([[-1.3831, -1.4610,  0.4911],\n",
      "        [-0.5749,  0.5623,  1.1037]])\n"
     ]
    }
   ],
   "source": [
    "# 특정 행 배열 추출하기\n",
    "print (data1[ [1, 2] ])\n",
    "print (data1[ [1, -1] ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d3584a2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.3831,  0.4911],\n",
      "        [ 0.1361, -0.0923]])\n",
      "tensor([[-1.3831],\n",
      "        [-0.5749]])\n"
     ]
    }
   ],
   "source": [
    "# 특정 행과 열 추출하기 (참고)\n",
    "print (data1[ [1, 2] ][:, [0, 2] ]) # 1, 2 행을 선택하고, 이 행들의 전체 행을 : 으로 선택한 후, 이 중에 0 과 2 의 열만 추출하기\n",
    "print (data1[ [1, -1] ][:, [0] ]) # 1, 2 행을 선택하고, 이 행들의 전체 행을 : 으로 선택한 후, 이 중에 0 의 열만 추출하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343569e1",
   "metadata": {},
   "source": [
    "### 텐서 복사: 텐서객체.clone().detach()\n",
    "- PyTorch 에서 tensor 를 복사하는 다양한 방법이 존재하지만, \n",
    "- 이 중에서, 위 메서드를 사용하는 것이 가장 깔끔한 방법이라고 함\n",
    "  - clone() : 기존 텐서객체의 내용을 복사한 텐서 생성\n",
    "  - detach() : 기존 텐서객체 그래프에서 분리된 텐서로 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b1c247cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "tensor([[1., 2.],\n",
      "        [4., 5.]])\n"
     ]
    }
   ],
   "source": [
    "data1 = torch.FloatTensor([ [1, 2, 3], [4, 5, 6] ])\n",
    "print (data1)\n",
    "data2 = data1[:2, :2]\n",
    "print (data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fa0f4bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [4., 4.]])\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 4., 6.]])\n"
     ]
    }
   ],
   "source": [
    "data2[1, 1] = 4\n",
    "print (data2)\n",
    "print (data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f1070362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "tensor([[1., 2.],\n",
      "        [4., 5.]])\n",
      "tensor([[1., 2.],\n",
      "        [4., 4.]])\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "data1 = torch.FloatTensor([ [1, 2, 3], [4, 5, 6] ])\n",
    "print (data1)\n",
    "data2 = data1[:2, :2].clone().detach() # .clone().detach() 로 복사하면 됨\n",
    "print (data2)\n",
    "data2[1, 1] = 4\n",
    "print (data2)\n",
    "print (data1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa6a261",
   "metadata": {},
   "source": [
    "### tensor 조건 연산: where()\n",
    "- torch.where(조건, 참일 때의 배열, 거짓일 때의 배열)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b37ebdc",
   "metadata": {},
   "source": [
    "#### 조건에 맞는 값 indexing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "feec17f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([1, 2, 4]),)\n",
      "tensor([2., 0., 1.])\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "data1 = torch.FloatTensor([7, 2, 0, 4, 1])\n",
    "index = torch.where(data1 < 3) # 조건에 맞는 인덱스 번호 리턴\n",
    "print(index)\n",
    "print(data1[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342555d2",
   "metadata": {},
   "source": [
    "#### 조건에 맞는 값 특정 다른 값으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "36c99275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([7., 2., 0., 4., 1.])\n",
      "tensor([ 1, -1, -1,  1, -1])\n"
     ]
    }
   ],
   "source": [
    "print(data1)\n",
    "data2 = torch.where(data1 < 3, -1, 1) # 조건에 맞으면 -1, 틀리면 1 로 원소 값을 수정\n",
    "print(data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6838ba",
   "metadata": {},
   "source": [
    "#### 다차원 배열에도 적용 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "216fcea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1, -1,  1],\n",
      "        [ 1,  1,  1]])\n"
     ]
    }
   ],
   "source": [
    "data1 = torch.FloatTensor([ [1, 2, 3], [4, 5, 6] ])\n",
    "data2 = torch.where(data1 < 3, -1, 1) # 조건에 맞으면 -1, 틀리면 1 로 원소 값을 수정\n",
    "print (data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f569f3b",
   "metadata": {},
   "source": [
    "### tensor 데이터 분석\n",
    "- min(), max(), sum(), mean(), var(), std() : 최대값, 최소값, 합계값, 평균값, 분산값, 표준편차값\n",
    "- argmin(), argmax() : 최소값의 인덱스 번호, 최대값의 인덱스 번호"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "26b35ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.)\n",
      "tensor(6.)\n",
      "tensor(21.)\n",
      "tensor(3.5000)\n",
      "tensor(3.5000)\n",
      "tensor(1.8708)\n",
      "tensor(0)\n",
      "tensor(5)\n"
     ]
    }
   ],
   "source": [
    "data1 = torch.FloatTensor([ [1, 2, 3], [4, 5, 6] ])\n",
    "print (data1.min())\n",
    "print (data1.max())\n",
    "print (data1.sum())\n",
    "print (data1.mean())\n",
    "print (data1.var())\n",
    "print (data1.std())\n",
    "print (data1.argmin())\n",
    "print (data1.argmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca742a4",
   "metadata": {},
   "source": [
    "### 텐서를 파일로 저장하고, 불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f624ca9a",
   "metadata": {},
   "source": [
    "#### 한 개의 텐서 저장 \n",
    "- save() 로 파일로 저장 가능 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "efd1feb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0000, 2.3333, 3.6667, 5.0000])\n"
     ]
    }
   ],
   "source": [
    "data1 = torch.linspace(1, 5, 4)\n",
    "print (data1)\n",
    "torch.save(data1, 'mydata1.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d53141",
   "metadata": {},
   "source": [
    "#### 한 개의 텐서 읽어오기 \n",
    "- load() 로 파일로 저장된 1차원 배열을 읽어올 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "32bb362c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0000, 2.3333, 3.6667, 5.0000])\n"
     ]
    }
   ],
   "source": [
    "data2 = torch.load('mydata1.pt')\n",
    "print (data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30a4da3",
   "metadata": {},
   "source": [
    "#### 한 개 이상의 텐서 저장 \n",
    "- 각 배열을 key=배열 로 key 값을 지정할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8703706f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0000, 2.3333, 3.6667, 5.0000])\n",
      "tensor([ 1.,  4.,  7., 10.])\n",
      "tensor([  1.,  34.,  67., 100.])\n"
     ]
    }
   ],
   "source": [
    "data1 = torch.linspace(1, 5, 4)\n",
    "data2 = torch.linspace(1, 10, 4)\n",
    "data3 = torch.linspace(1, 100, 4)\n",
    "print (data1)\n",
    "print (data2)\n",
    "print (data3)\n",
    "datas = {'data1': data1, 'data2': data2, 'data3': data3}\n",
    "torch.save(datas, 'mydata1.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "dfa94433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0000, 2.3333, 3.6667, 5.0000])\n",
      "tensor([ 1.,  4.,  7., 10.])\n",
      "tensor([  1.,  34.,  67., 100.])\n"
     ]
    }
   ],
   "source": [
    "datas = torch.load('mydata1.pt')\n",
    "print (datas['data1'])\n",
    "print (datas['data2'])\n",
    "print (datas['data3'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e308e751",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block\" style=\"border: 2px solid #1976D2;background-color:#E3F2FD;padding:5px;font-size:0.9em;\">\n",
    "본 자료는 저작권법 제25조 2항에 의해 보호를 받습니다. 본 자료를 외부에 공개하지 말아주세요.<br>\n",
    "<b><a href=\"https://school.fun-coding.org/\">잔재미코딩 (https://school.fun-coding.org/)</a> 에서 본 강의를 포함하는 최적화된 로드맵도 확인하실 수 있습니다</b></div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
