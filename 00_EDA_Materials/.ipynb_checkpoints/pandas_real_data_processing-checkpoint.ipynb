{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block\" style=\"border: 2px solid #1976D2;background-color:#E3F2FD;padding:5px;font-size:0.9em;\">\n",
    "본 자료는 저작권법 제25조 2항에 의해 보호를 받습니다. 본 자료를 외부에 공개하지 말아주세요.<br>\n",
    "본 강의만 잘 정리하면, 데이터 분석과 데이터 과학(머신러닝, 인공지능) 모두 가능합니다!<br>\n",
    "<b><a href=\"https://school.fun-coding.org/\">잔재미코딩</a> 에서 본 강의 기반 최적화된 로드맵도 확인하실 수 있습니다</b></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## raw data를 pandas와 파이썬으로 조작해서 그래프 만들어보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 데이터 시각화란?\n",
    "- 데이터 분석 결과를 쉽게 이해할 수 있도록 시각적으로 표현하고 전달되는 과정\n",
    "- 탐색적 데이터 분석, 데이터 처리, 데이터 예측 모든 경우, 결과를 알아보기 쉽게 하기 위해 데이터 시각화는 필수적임\n",
    "- 다양한 시각화 기법 중, 가장 최신의 흥미로운 데이터 시각화 과정을 진행해보기로 함\n",
    "  - https://app.flourish.studio\n",
    "  - https://public.flourish.studio/visualisation/2897018/\n",
    "\n",
    "### 지금까지 익힌 데이터 처리 기술을 기반으로 데이터 시각화를 위해, raw data를 포멧에 맞추어 변환하여 그래프를 만들어보기로 함\n",
    "<img src=\"https://www.fun-coding.org/00_Images/covid_graph_ex2.jpg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 데이터 시각화를 위한 데이터 포멧 이해\n",
    "- 데이터 시각화를 위해, raw data를 변환해야 함\n",
    "- 지금까지 익힌 데이터 처리 기술을 사용해서, 데이터를 변환하기로 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 필요 데이터\n",
    "  - 국가명, 국기, 날짜별 확진자 수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.fun-coding.org/00_Images/covid_ex_data_format.jpg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. raw data 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "PATH = \"COVID-19-master/csse_covid_19_data/csse_covid_19_daily_reports/\"\n",
    "doc = pd.read_csv(PATH + \"04-01-2020.csv\", encoding='utf-8-sig')\n",
    "doc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "PATH = \"COVID-19-master/csse_covid_19_data/csse_covid_19_daily_reports/\"\n",
    "doc = pd.read_csv(PATH + \"03-01-2020.csv\", encoding='utf-8-sig')\n",
    "doc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 3월 중순 데이터까지는 컬럼명이 Province/State, Country/Region 이고, 이후에는 Province_State, Country_Region 이므로, try except 구문을 사용해서, 데이터 조작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = pd.read_csv(PATH + \"01-22-2020.csv\", encoding='utf-8-sig')\n",
    "try:\n",
    "    doc = doc[['Province_State', 'Country_Region', 'Confirmed']]  # 1. 특정 컬럼만 선택해서 데이터프레임 만들기\n",
    "except:\n",
    "    doc = doc[['Province/State', 'Country/Region', 'Confirmed']]  # 1. 특정 컬럼만 선택해서 데이터프레임 만들기\n",
    "    doc.columns = ['Province_State', 'Country_Region', 'Confirmed']\n",
    "    \n",
    "doc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 데이터프레임 데이터 변환하기\n",
    "1. 특정 컬럼만 선택해서 데이터프레임 만들기\n",
    "2. 특정 컬럼에 없는 데이터 삭제하기\n",
    "3. 특정 컬럼의 데이터 타입 변경하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "PATH = \"COVID-19-master/csse_covid_19_data/csse_covid_19_daily_reports/\"\n",
    "\n",
    "doc = pd.read_csv(PATH + \"01-22-2020.csv\", encoding='utf-8-sig')\n",
    "try:\n",
    "    doc = doc[['Province_State', 'Country_Region', 'Confirmed']]  # 1. 특정 컬럼만 선택해서 데이터프레임 만들기\n",
    "except:\n",
    "    doc = doc[['Province/State', 'Country/Region', 'Confirmed']]  # 1. 특정 컬럼만 선택해서 데이터프레임 만들기\n",
    "    doc.columns = ['Province_State', 'Country_Region', 'Confirmed']\n",
    "doc = doc.dropna(subset=['Confirmed'])     # 2. 특정 컬럼에 없는 데이터 삭제하기\n",
    "doc = doc.astype({'Confirmed': 'int64'})   # 3. 특정 컬럼의 데이터 타입 변경하기\n",
    "doc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 국가 정보 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_info = pd.read_csv(\"COVID-19-master/csse_covid_19_data/UID_ISO_FIPS_LookUp_Table.csv\", encoding='utf-8-sig')\n",
    "country_info.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 두 데이터프레임 합쳐보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.merge(doc, country_info, how='left', on='Country_Region')\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 잘못 매칭된 국가 정보 확인하기\n",
    "  - iso2 컬럼이 매칭되지 않은 확진자수 국가 확인해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_rows = test_df[test_df['iso2'].isnull()]\n",
    "nan_rows.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 컬럼값 변경하기\n",
    "- Country_Region 국가명이 다양한 경우가 많았음\n",
    "- 각 케이스를 일괄적으로 변경할 키값이 존재하지 않고, 키가 될 수 있는 컬럼도 다양하고, 각 파일마다 키가 될 수 있는 컬럼이 변경되어, 키값으로 매칭이 불가하였음\n",
    "- 이에 각 케이스를 직접 확인해서, 국가명을 일관되게 변경할 수 있도록 별도 json 파일 작성\n",
    "- json 파일 기반으로 국가명을 일관되게 변경하기로 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### json.load() 함수로 파일로된 json 데이터를 사전처럼 다룰 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('COVID-19-master/csse_covid_19_data/country_convert.json', 'r', encoding='utf-8-sig') as json_file:\n",
    "    json_data = json.load(json_file)\n",
    "    print (json_data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### apply() 함수 사용법\n",
    "- apply() 함수를 사용해서, 특정 컬럼값 변경 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    '영어': [60, 70],\n",
    "    '수학': [100, 50]\n",
    "}, index = ['Dave', 'David'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(df_data):\n",
    "    print (type(df_data))    \n",
    "    print (df_data.index)\n",
    "    print (df_data.values)    \n",
    "    return df_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 참고로 행이 두개 인데, 3번 func가 호출되는 이유는 apply() 함수 자체가, 첫 번째 행에 대해서는 두번 호출하도록 구현되어 있기 때문임 (전체 행의 처리를 위한 최적화 기법 적용 가능 여부를 확인코자 이와 같이 구현됨)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_func = df.apply(func, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_func = df.apply(func, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    '영어': [60, 70],\n",
    "    '수학': [100, 50]\n",
    "}, index = ['Dave', 'David'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(df_data):\n",
    "    df_data['영어'] = 80\n",
    "    return df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_func = df.apply(func, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### apply() 함수를 사용해서, 국가 컬럼값 변경하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 사전 작업 (doc 변수로 데이터프레임 파일 만들기)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "doc = pd.read_csv(PATH + \"01-22-2020.csv\", encoding='utf-8-sig')\n",
    "try:\n",
    "    doc = doc[['Province_State', 'Country_Region', 'Confirmed']]  # 1. 특정 컬럼만 선택해서 데이터프레임 만들기\n",
    "except:\n",
    "    doc = doc[['Province/State', 'Country/Region', 'Confirmed']]  # 1. 특정 컬럼만 선택해서 데이터프레임 만들기\n",
    "    doc.columns = ['Province_State', 'Country_Region', 'Confirmed']\n",
    "doc = doc.dropna(subset=['Confirmed'])     # 2. 특정 컬럼에 없는 데이터 삭제하기\n",
    "doc = doc.astype({'Confirmed': 'int64'})   # 3. 특정 컬럼의 데이터 타입 변경하기\n",
    "doc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 변경할 국가명을 가지고 있는 json 파일 읽기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('COVID-19-master/csse_covid_19_data/country_convert.json', 'r', encoding='utf-8-sig') as json_file:\n",
    "    json_data = json.load(json_file)\n",
    "    print (json_data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Country_Region 이라는 컬럼값을 확인해서, 국가명이 다르게 기재되어 있을 경우에만, 지정한 국가명으로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(row):\n",
    "    if row['Country_Region'] in json_data:\n",
    "        row['Country_Region'] = json_data[row['Country_Region']]\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = doc.apply(func, axis=1)\n",
    "doc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 참고: 파일명으로 데이터 변환하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- lstrip(): 앞에(왼쪽에)서 특정 데이터 삭제하기, rstrip(): 뒤에(오른쪽에)서 특정 데이터 삭제하기\n",
    "- replace(변경전데이터, 변경후데이터): 문자열에서 변경전데이터 를 변경후데이터 로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"01-22-2020.csv\"\n",
    "date_column = data.split(\".\")[0].lstrip('0').replace('-', '/')\n",
    "date_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"01-22-2020.csv\"\n",
    "data.split('.')[0].lstrip(\"0\").replace('-', '/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.columns = ['Province_State', 'Country_Region', date_column]\n",
    "doc.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 중복 데이터 합치기\n",
    "- groupby() : 그룹별로 데이터를 집계하는 함수\n",
    "  - 동일한 컬럼값으로 묶어서 통계 또는 평균등을 확인할 수 있음 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    '성별': ['남', '남', '남'],\n",
    "    '이름': ['David', 'Dave', 'Dave'],\n",
    "    '수학': [100, 50, 80],\n",
    "    '국어': [80, 70, 50]    \n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.groupby('이름').mean() 메서드는 숫자 컬럼에 대해서만 계산 가능합니다.\n",
    "# 기존에는 df.groupby('이름').mean() 호출시, 숫자 컬럼 외에는 자동 제외하고 계산하였으나, 최근 버전에서는 자동 제외되지 않으므로,\n",
    "# 다음과 같이 숫자 컬럼만을 강제로 선택한 후, df.groupby('이름').mean() 을 호출하면 좋을 것 같습니다.\n",
    "selected_columns = ['이름', '수학', '국어']\n",
    "df = df[selected_columns]\n",
    "\n",
    "df.groupby('이름').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('이름').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 국가별 총 확진자수 구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "doc = pd.read_csv(PATH + \"01-22-2020.csv\", encoding='utf-8-sig')\n",
    "try:\n",
    "    doc = doc[['Province_State', 'Country_Region', 'Confirmed']]  # 1. 특정 컬럼만 선택해서 데이터프레임 만들기\n",
    "except:\n",
    "    doc = doc[['Province/State', 'Country/Region', 'Confirmed']]  # 1. 특정 컬럼만 선택해서 데이터프레임 만들기\n",
    "    doc.columns = ['Province_State', 'Country_Region', 'Confirmed']\n",
    "doc = doc.dropna(subset=['Confirmed'])     # 2. 특정 컬럼에 없는 데이터 삭제하기\n",
    "doc = doc.astype({'Confirmed': 'int64'})   # 3. 특정 컬럼의 데이터 타입 변경하기\n",
    "doc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.groupby('Country_Region').sum()  # 4. Country_Region 컬럼값이 동일한 케이스를 그룹화해서, 각 그룹별 합계 확인하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 데이터 전처리하기\n",
    "- 지금까지의 과정을 모두 한데 모아서, 함수로 만들기\n",
    "  1. csv 파일 읽기\n",
    "  2. 'Country_Region', 'Confirmed' 두 개의 컬럼만 가져오기\n",
    "  3. 'Confirmed' 에 데이터가 없는 행 삭제하기\n",
    "  4. 'Country_Region'의 국가명을 여러 파일에 일관되게 변경하기\n",
    "  5. 'Confirmed' 데이터 타입을 int64(정수) 로 변경\n",
    "  6. 'Country_Region' 를 기준으로 중복된 데이터를 합치기\n",
    "  7. 파일명을 기반으로 날짜 문자열 변환하고, 'Confirmed' 컬럼명 변경하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('COVID-19-master/csse_covid_19_data/country_convert.json', 'r', encoding='utf-8-sig') as json_file:\n",
    "    json_data = json.load(json_file)\n",
    "\n",
    "def country_name_convert(row):\n",
    "    if row['Country_Region'] in json_data:\n",
    "        return json_data[row['Country_Region']]\n",
    "    return row['Country_Region']\n",
    "\n",
    "def create_dateframe(filename):\n",
    "\n",
    "    doc = pd.read_csv(PATH + filename, encoding='utf-8-sig')  # 1. csv 파일 읽기\n",
    "    try:\n",
    "        doc = doc[['Country_Region', 'Confirmed']]  # 2. 특정 컬럼만 선택해서 데이터프레임 만들기\n",
    "    except:\n",
    "        doc = doc[['Country/Region', 'Confirmed']]  # 2. 특정 컬럼만 선택해서 데이터프레임 만들기\n",
    "        doc.columns = ['Country_Region', 'Confirmed']\n",
    "    doc = doc.dropna(subset=['Confirmed'])     # 3. 특정 컬럼에 없는 데이터 삭제하기\n",
    "    doc['Country_Region'] = doc.apply(country_name_convert, axis=1)   # 4. 'Country_Region'의 국가명을 여러 파일에 일관되게 변경하기\n",
    "    doc = doc.astype({'Confirmed': 'int64'})   # 5. 특정 컬럼의 데이터 타입 변경하기\n",
    "    doc = doc.groupby('Country_Region').sum()  # 6. 특정 컬럼으로 중복된 데이터를 합치기\n",
    "\n",
    "    # 7. 파일명을 기반으로 날짜 문자열 변환하고, 'Confirmed' 컬럼명 변경하기\n",
    "    date_column = filename.split(\".\")[0].lstrip('0').replace('-', '/') \n",
    "    doc.columns = [date_column]\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 테스트해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = create_dateframe(\"01-22-2020.csv\")\n",
    "doc2 = create_dateframe(\"04-01-2020.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터프레임 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = pd.merge(doc1, doc2, how='outer', left_index=True, right_index=True)\n",
    "doc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 없는 데이터는 0으로 값 대체하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = doc.fillna(0)\n",
    "doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 참고: 특정 폴더 파일 리스트 확인하기\n",
    "- split() 함수를 사용해서 특정 확장자를 가진 파일 리스트만 추출 가능\n",
    "- 문자열변수.split('.') 은 ['파일명', '확장자'] 와 같은 리스트가 반환되므로, 문자열변수.split('.')[-1] 을 통해, 이 중에서 마지막 아이템을 선택하면 됨\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "PATH = 'COVID-19-master/csse_covid_19_data/csse_covid_19_daily_reports/'\n",
    "file_list = os.listdir(PATH)\n",
    "csv_list = list()\n",
    "\n",
    "for file in file_list:\n",
    "    if file.split(\".\")[-1] == 'csv':\n",
    "        csv_list.append(file)\n",
    "\n",
    "print (csv_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 참고: 리스트 정렬\n",
    "- 리스트변수.sort() : 오름차순 정렬 (디폴트)\n",
    "- 리스트변수.sort(reverse=True) : 내림차순 정렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_list.sort()\n",
    "csv_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 여러 데이터 수집, 전처리해서, 하나의 데이터프레임 만들기\n",
    "- 지금까지의 과정을 모두 한데 모아서, 함수로 만들기\n",
    "  1. 필요한 파일 리스트만 추출하기\n",
    "  2. 파일 리스트 정렬하기\n",
    "  3. 데이터프레임 전처리하기 (별도 create_dateframe() 함수)\n",
    "  4. 데이터프레임 합치기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 최종 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "with open('COVID-19-master/csse_covid_19_data/country_convert.json', 'r', encoding='utf-8-sig') as json_file:\n",
    "    json_data = json.load(json_file)\n",
    "\n",
    "def country_name_convert(row):\n",
    "    if row['Country_Region'] in json_data:\n",
    "        return json_data[row['Country_Region']]\n",
    "    return row['Country_Region']\n",
    "\n",
    "def create_dateframe(filename):\n",
    "\n",
    "    doc = pd.read_csv(PATH + filename, encoding='utf-8-sig')  # 1. csv 파일 읽기\n",
    "    try:\n",
    "        doc = doc[['Country_Region', 'Confirmed']]  # 2. 특정 컬럼만 선택해서 데이터프레임 만들기\n",
    "    except:\n",
    "        doc = doc[['Country/Region', 'Confirmed']]  # 2. 특정 컬럼만 선택해서 데이터프레임 만들기\n",
    "        doc.columns = ['Country_Region', 'Confirmed']\n",
    "    doc = doc.dropna(subset=['Confirmed'])     # 3. 특정 컬럼에 없는 데이터 삭제하기\n",
    "    doc['Country_Region'] = doc.apply(country_name_convert, axis=1)   # 4. 'Country_Region'의 국가명을 여러 파일에 일관되게 변경하기\n",
    "    doc = doc.astype({'Confirmed': 'int64'})   # 5. 특정 컬럼의 데이터 타입 변경하기\n",
    "    doc = doc.groupby('Country_Region').sum()  # 6. 특정 컬럼으로 중복된 데이터를 합치기\n",
    "\n",
    "    # 7. 파일명을 기반으로 날짜 문자열 변환하고, 'Confirmed' 컬럼명 변경하기\n",
    "    date_column = filename.split(\".\")[0].lstrip('0').replace('-', '/') \n",
    "    doc.columns = [date_column]\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def generate_dateframe_by_path(PATH):\n",
    "\n",
    "    file_list, csv_list = os.listdir(PATH), list()\n",
    "    first_doc = True\n",
    "    for file in file_list:\n",
    "        if file.split(\".\")[-1] == 'csv':\n",
    "            csv_list.append(file)\n",
    "    csv_list.sort()\n",
    "    \n",
    "    for file in csv_list:\n",
    "        doc = create_dateframe(file)\n",
    "        if first_doc:\n",
    "            final_doc, first_doc = doc, False\n",
    "        else:\n",
    "            final_doc = pd.merge(final_doc, doc, how='outer', left_index=True, right_index=True)\n",
    "\n",
    "    final_doc = final_doc.fillna(0)\n",
    "    return final_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'COVID-19-master/csse_covid_19_data/csse_covid_19_daily_reports/'\n",
    "doc = generate_dateframe_by_path(PATH)\n",
    "doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 참고: 데이터 타입 변환이 가능한 모든 열의 데이터 타입 변경\n",
    "- pd.astype(데이터타입)\n",
    "  - object 는 파이썬의 str 또는 혼용 데이터 타입 (문자열)\n",
    "  - int64 는 파이썬의 int (정수)\n",
    "  - float64 는 파이썬의 float (부동소숫점)\n",
    "  - bool 는 파이썬의 bool (True 또는 False 값을 가지는 boolean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = doc.astype('int64')\n",
    "doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pandas 라이브러리로 csv 파일 쓰기\n",
    "- pandas dataframe 데이터를 csv 파일로 저장하기 위해, to_csv() 함수 사용\n",
    "    ```\n",
    "    doc.to_csv(\"00_data/students_default.csv\")\n",
    "    ```\n",
    "\n",
    "- encoding 옵션 사용 가능\n",
    "    ```\n",
    "    doc.to_csv(\"00_data/students_default.csv\", encoding='utf-8-sig')\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.to_csv(\"COVID-19-master/final_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block\" style=\"border: 2px solid #1976D2;background-color:#E3F2FD;padding:5px;font-size:0.9em;\">\n",
    "본 자료는 저작권법 제25조 2항에 의해 보호를 받습니다. 본 자료를 외부에 공개하지 말아주세요.<br>\n",
    "본 강의만 잘 정리하면, 데이터 분석과 데이터 과학(머신러닝, 인공지능) 모두 가능합니다!<br>\n",
    "<b><a href=\"https://school.fun-coding.org/\">잔재미코딩</a> 에서 본 강의 기반 최적화된 로드맵도 확인하실 수 있습니다</b></div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
