{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P4HSk8x_20m5"
   },
   "source": [
    "### Kaggle 문제\n",
    "- https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zm349cM303yH",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "YVlrQ1737qMz",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OKPPHYbE7uyP",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Setup seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QPK7l1p37whz",
    "outputId": "40d16f21-5b15-4dd8-8c80-dad6c8cd1ac4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "\n",
    "# device 설정\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print (device)\n",
    "\n",
    "seed = 42 # seed 값 설정\n",
    "random.seed(seed) # 파이썬 난수 생성기 \n",
    "os.environ['PYTHONHASHSEED'] = str(seed) # 해시 시크릿값 고정\n",
    "np.random.seed(seed) # 넘파이 난수 생성기 \n",
    "\n",
    "torch.manual_seed(seed) # 파이토치 CPU 난수 생성기\n",
    "torch.backends.cudnn.deterministic = True # 확정적 연산 사용 설정\n",
    "torch.backends.cudnn.benchmark = False   # 벤치마크 기능 사용 해제\n",
    "torch.backends.cudnn.enabled = False        # cudnn 기능 사용 해제\n",
    "\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed(seed) # 파이토치 GPU 난수 생성기\n",
    "    torch.cuda.manual_seed_all(seed) # 파이토치 멀티 GPU 난수 생성기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5cHQbIPG76lw",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Connect Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O7jDTJ5173Lk",
    "outputId": "e09f430d-4fd2-4b18-c814-2d349149f00b",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XW2_4NXU8RZU",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C3hCpZZy79hA",
    "outputId": "c81c53b8-6829-43b9-faf4-44028daa580a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22500 2500\n"
     ]
    }
   ],
   "source": [
    "import os, shutil\n",
    "original_data_path = '/content/drive/MyDrive/Colab Notebooks/00_data/dogs-vs-cats'\n",
    "os.makedirs('dogsvscats', exist_ok=True)\n",
    "import zipfile\n",
    "with zipfile.ZipFile(os.path.join(original_data_path, 'train.zip')) as train_zip:\n",
    "    train_zip.extractall('/content/dogsvscats')\n",
    "    \n",
    "with zipfile.ZipFile(os.path.join(original_data_path, 'test.zip')) as test_zip:\n",
    "    test_zip.extractall('/content/dogsvscats')\n",
    "\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_dir = '/content/dogsvscats/train'\n",
    "test_dir = '/content/dogsvscats/test'\n",
    "all_train_files = glob.glob(os.path.join(train_dir, '*.jpg'))\n",
    "test_list = glob.glob(os.path.join(test_dir, '*.jpg'))\n",
    "train_labels = [path.split('/')[-1].split('.')[0] for path in all_train_files]\n",
    "train_list, val_list = train_test_split(all_train_files, test_size = 0.1, stratify = train_labels, random_state=seed)\n",
    "print (len(train_list), len(val_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rjSuwnFK8g0y",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "P0-QDNGM8QGU",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "input_size = 224\n",
    "transforms_for_train =  transforms.Compose([\n",
    "        transforms.RandomResizedCrop(input_size, scale=(0.5, 1.0)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "transforms_for_val_test = transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.CenterCrop(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "#class Dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, file_list, transform=None):\n",
    "        self.file_list = file_list\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.file_list[idx]\n",
    "        if img_path.split('/')[-1][-3:] == 'jpg':\n",
    "            img = Image.open(img_path)     \n",
    "            if self.transform is not None:\n",
    "                img_transform = self.transform(img)\n",
    "                label = img_path.split('/')[-1].split('.')[0]\n",
    "                if label == 'dog':\n",
    "                  label = 1\n",
    "                elif label == 'cat':\n",
    "                  label = 0\n",
    "        return img_transform, label\n",
    "\n",
    "dataset_train = CustomDataset(train_list, transform=transforms_for_train)\n",
    "dataset_valid = CustomDataset(val_list, transform=transforms_for_val_test)\n",
    "dataset_test = CustomDataset(test_list, transform=transforms_for_val_test)\n",
    "\n",
    "from torch.utils.data import DataLoader # 데이터 로더 클래스\n",
    "\n",
    "train_batches = DataLoader(dataset=dataset_train, batch_size=8, shuffle=True)\n",
    "val_batches = DataLoader(dataset=dataset_valid, batch_size=8, shuffle=False)\n",
    "test_batches = DataLoader(dataset=dataset_test, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CGjV-Xcz8nTO",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wG1rWS208kRN",
    "outputId": "fbd5366c-67f8-43de-ddbe-53283b01812a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 509 kB 4.1 MB/s \n",
      "\u001b[K     |████████████████████████████████| 4.9 MB 84.7 MB/s \n",
      "\u001b[K     |████████████████████████████████| 120 kB 70.9 MB/s \n",
      "\u001b[K     |████████████████████████████████| 6.6 MB 47.1 MB/s \n",
      "\u001b[?25h  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "!pip install -q timm efficientnet_pytorch==0.7.1 transformers==4.22.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "-Kdgz7ZYbIbq",
    "outputId": "8b2a346a-f0f3-47f8-9e3c-0fb6d356c8f8",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\nfrom transformers import get_linear_schedule_with_warmup\\nscheduler = get_linear_schedule_with_warmup(\\n  optimizer, \\n  num_warmup_steps = 0, \\n  num_training_steps = 10\\n)\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import timm\n",
    "\n",
    "model = timm.create_model(\"vit_base_patch32_224_in21k\", pretrained=True)\n",
    "model.head = nn.Sequential(\n",
    "    nn.Linear(768, 21843, bias=True),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.BatchNorm1d(21843),\n",
    "    nn.Linear(21843, 512, bias=True),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.BatchNorm1d(512),\n",
    "    nn.Linear(512, 1, bias=True),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "model.to(device)\n",
    "loss_func = nn.BCELoss()\n",
    "# optimizer = torch.optim.AdamW(model.parameters(), weight_decay=0.001)\n",
    "# optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5, weight_decay=0.0001)\n",
    "# optimizer = torch.optim.Adamax(model.parameters(), lr=1e-5)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "'''\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "  optimizer, \n",
    "  num_warmup_steps = 0, \n",
    "  num_training_steps = 10\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5lZUir1v9TPw",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Define Train Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "sxO6MCPm8-as",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, early_stop, epochs, train_loader, valid_loader):\n",
    "    train_losses, train_accuracies, valid_losses, valid_accuracies, lowest_loss, lowest_epoch = list(), list(), list(), list(), np.inf, 0\n",
    "    \n",
    "    # DEBUG\n",
    "    progress_count = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train_loss, train_accuracy, train_corrects, valid_loss, valid_accuracy, valid_corrects = 0, 0, 0, 0, 0, 0\n",
    "        train_correct, valid_correct = 0, 0\n",
    "\n",
    "        start = time.time()\n",
    "        model.train()\n",
    "        for train_x, train_y in train_loader:\n",
    "            train_x = train_x.to(device)\n",
    "            train_y = train_y.to(device).float()\n",
    "            train_y = train_y.view(train_y.size(0), -1)\n",
    "            pred = model(train_x)\n",
    "            loss = criterion(pred, train_y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "            y_pred = np.round(pred.detach().cpu())\n",
    "            train_correct += y_pred.eq(train_y.detach().cpu()).sum().item()\n",
    "            \n",
    "            # DEBUG \n",
    "            # if (progress_count % 10) == 0:\n",
    "            #    print (y_pred.eq(train_y.detach().cpu()).sum().item(), len(y_pred))\n",
    "            # progress_count += 1\n",
    "            \n",
    "\n",
    "        train_loss = train_loss / len(train_loader)\n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracy = train_correct / len(train_loader.dataset)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for valid_x, valid_y in valid_loader:\n",
    "                valid_x = valid_x.to(device)\n",
    "                valid_y = valid_y.to(device).float()\n",
    "                valid_y = valid_y.view(valid_y.size(0), -1)\n",
    "                pred = model(valid_x)\n",
    "                loss = criterion(pred, valid_y)\n",
    "                valid_loss += loss.item()\n",
    "            \n",
    "                y_pred = np.round(pred.detach().cpu())\n",
    "                valid_correct += y_pred.eq(valid_y.detach().cpu()).sum().item()\n",
    "\n",
    "        valid_loss = valid_loss / len(valid_loader)\n",
    "        valid_losses.append(valid_loss)\n",
    "        valid_accuracy = valid_correct / len(valid_loader.dataset)\n",
    "        valid_accuracies.append(valid_accuracy)\n",
    "        \n",
    "        elapsed_time = time.time() - start\n",
    "        print(f'[Epoch {epoch+1}/{epochs}]: {elapsed_time:.3f} sec(elapsed time), train loss: {train_losses[-1]:.4f}, train acc: {train_accuracy * 100:.3f}% / valid loss: {valid_losses[-1]:.4f}, valid acc: {valid_accuracy * 100:.3f}%')\n",
    "\n",
    "        if valid_losses[-1] < lowest_loss:\n",
    "            lowest_loss = valid_losses[-1]\n",
    "            lowest_epoch = epoch\n",
    "            best_model = deepcopy(model.state_dict())\n",
    "        else:\n",
    "            if (early_stop > 0) and lowest_epoch + early_stop < epoch:\n",
    "                print (\"Early Stopped\", epoch, \"epochs\")\n",
    "                break\n",
    "        \n",
    "        # scheduler.step()\n",
    "\n",
    "    model.load_state_dict(best_model)        \n",
    "    return model, lowest_loss, train_losses, valid_losses, train_accuracies, valid_accuracies\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AtLQyQo690dv",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CkzlcRl-9uhm",
    "outputId": "e28ce6ed-732d-497c-8043-258926cec71a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/30]: 337.143 sec(elapsed time), train loss: 0.1213, train acc: 95.751% / valid loss: 0.0280, valid acc: 99.080%\n",
      "[Epoch 2/30]: 336.717 sec(elapsed time), train loss: 0.0760, train acc: 97.467% / valid loss: 0.0245, valid acc: 99.160%\n",
      "[Epoch 3/30]: 336.072 sec(elapsed time), train loss: 0.0604, train acc: 98.049% / valid loss: 0.0384, valid acc: 98.720%\n",
      "[Epoch 4/30]: 335.443 sec(elapsed time), train loss: 0.0541, train acc: 98.213% / valid loss: 0.0221, valid acc: 99.320%\n",
      "[Epoch 5/30]: 335.887 sec(elapsed time), train loss: 0.0475, train acc: 98.409% / valid loss: 0.0280, valid acc: 99.320%\n",
      "[Epoch 6/30]: 333.666 sec(elapsed time), train loss: 0.0421, train acc: 98.644% / valid loss: 0.0311, valid acc: 99.040%\n",
      "[Epoch 7/30]: 333.256 sec(elapsed time), train loss: 0.0366, train acc: 98.782% / valid loss: 0.0294, valid acc: 99.040%\n",
      "[Epoch 8/30]: 334.000 sec(elapsed time), train loss: 0.0377, train acc: 98.738% / valid loss: 0.0243, valid acc: 99.200%\n",
      "[Epoch 9/30]: 332.741 sec(elapsed time), train loss: 0.0378, train acc: 98.738% / valid loss: 0.0268, valid acc: 99.000%\n",
      "[Epoch 10/30]: 333.698 sec(elapsed time), train loss: 0.0356, train acc: 98.684% / valid loss: 0.0328, valid acc: 98.800%\n",
      "[Epoch 11/30]: 333.054 sec(elapsed time), train loss: 0.0297, train acc: 98.964% / valid loss: 0.0244, valid acc: 99.160%\n",
      "[Epoch 12/30]: 333.084 sec(elapsed time), train loss: 0.0297, train acc: 98.969% / valid loss: 0.0260, valid acc: 99.160%\n",
      "[Epoch 13/30]: 335.906 sec(elapsed time), train loss: 0.0303, train acc: 98.933% / valid loss: 0.0433, valid acc: 98.720%\n",
      "[Epoch 14/30]: 337.431 sec(elapsed time), train loss: 0.0264, train acc: 99.093% / valid loss: 0.0237, valid acc: 99.240%\n",
      "[Epoch 15/30]: 336.369 sec(elapsed time), train loss: 0.0280, train acc: 98.956% / valid loss: 0.0260, valid acc: 99.320%\n",
      "[Epoch 16/30]: 338.092 sec(elapsed time), train loss: 0.0249, train acc: 99.053% / valid loss: 0.0261, valid acc: 99.280%\n",
      "[Epoch 17/30]: 337.936 sec(elapsed time), train loss: 0.0248, train acc: 99.076% / valid loss: 0.0324, valid acc: 99.200%\n",
      "[Epoch 18/30]: 337.225 sec(elapsed time), train loss: 0.0259, train acc: 98.991% / valid loss: 0.0195, valid acc: 99.360%\n",
      "[Epoch 19/30]: 338.105 sec(elapsed time), train loss: 0.0241, train acc: 99.093% / valid loss: 0.0226, valid acc: 99.280%\n",
      "[Epoch 20/30]: 334.110 sec(elapsed time), train loss: 0.0252, train acc: 99.062% / valid loss: 0.0319, valid acc: 99.200%\n",
      "[Epoch 21/30]: 333.342 sec(elapsed time), train loss: 0.0216, train acc: 99.169% / valid loss: 0.0389, valid acc: 99.200%\n",
      "[Epoch 22/30]: 332.232 sec(elapsed time), train loss: 0.0215, train acc: 99.342% / valid loss: 0.0370, valid acc: 99.080%\n",
      "[Epoch 23/30]: 332.928 sec(elapsed time), train loss: 0.0235, train acc: 99.049% / valid loss: 0.0431, valid acc: 99.160%\n",
      "[Epoch 24/30]: 333.396 sec(elapsed time), train loss: 0.0279, train acc: 99.116% / valid loss: 0.0264, valid acc: 99.240%\n",
      "[Epoch 25/30]: 332.064 sec(elapsed time), train loss: 0.0290, train acc: 98.956% / valid loss: 0.0295, valid acc: 99.080%\n",
      "[Epoch 26/30]: 332.608 sec(elapsed time), train loss: 0.0209, train acc: 99.311% / valid loss: 0.0299, valid acc: 99.240%\n",
      "[Epoch 27/30]: 333.124 sec(elapsed time), train loss: 0.0237, train acc: 99.191% / valid loss: 0.0481, valid acc: 99.120%\n",
      "[Epoch 28/30]: 333.966 sec(elapsed time), train loss: 0.0204, train acc: 99.249% / valid loss: 0.0502, valid acc: 98.880%\n",
      "[Epoch 29/30]: 334.390 sec(elapsed time), train loss: 0.0174, train acc: 99.320% / valid loss: 0.0359, valid acc: 99.160%\n",
      "[Epoch 30/30]: 335.039 sec(elapsed time), train loss: 0.0182, train acc: 99.320% / valid loss: 0.0427, valid acc: 99.160%\n"
     ]
    }
   ],
   "source": [
    "model, lowest_loss, train_losses, valid_losses, train_accuracies, valid_accuracies = train_model(model, loss_func, optimizer, 0, 30, train_batches, val_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6-V5ojwF_qwr",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KoK3SEhT_plX",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "PATH = '/content/drive/MyDrive/Colab Notebooks/00_data/dogs-vs-cats/'\n",
    "torch.save(model.state_dict(), PATH + 'model_vit_base_patch32_224_in21k_without_scheduler_adam_1e5_epoch30.pth')  # 모델 객체의 state_dict 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-gFnQzLewitS",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1fjX3LPtwhxO",
    "outputId": "c01d6d1d-a44e-42d3-f299-f821d5cd30aa",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = '/content/drive/MyDrive/Colab Notebooks/00_data/dogs-vs-cats/'\n",
    "model.load_state_dict(torch.load(PATH + 'model_vit_base_patch32_224_in21k_without_scheduler_adam_1e5_epoch30.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NSy5d-PS_hxM",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Predict & Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "A7k0o_4D98RI",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_list = glob.glob(os.path.join(test_dir, '*.jpg'))\n",
    "dataset_test = CustomDataset(test_list, transform=transforms_for_val_test)\n",
    "test_batches = DataLoader(dataset=dataset_test, batch_size=8, shuffle=False)\n",
    "\n",
    "def predict(model, data_loader):\n",
    "    ids = list()\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        ret = None\n",
    "        for img, fileid in data_loader:\n",
    "            img = img.to(device)\n",
    "            pred = model(img)\n",
    "            ids += list(fileid)\n",
    "            if ret is None:\n",
    "                ret = pred.cpu().numpy()\n",
    "            else:\n",
    "                ret = np.vstack([ret, pred.cpu().numpy()])\n",
    "    return ret, ids\n",
    "   \n",
    "pred, ids = predict(model, test_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eLh-DTcoz3lZ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "AfHASgsfxhSx",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id': ids, 'label': np.clip(pred, 0.006, 1-0.006).squeeze()})\n",
    "submission.sort_values(by='id', inplace=True)\n",
    "submission.reset_index(drop=True, inplace=True)\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QlCVV3UZXTwL",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Test for Optimal Cliping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I6Up5U9tyHmu",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id': ids, 'label': np.clip(pred, 0.007, 1-0.007).squeeze()})\n",
    "submission.sort_values(by='id', inplace=True)\n",
    "submission.reset_index(drop=True, inplace=True)\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
