{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block\" style=\"border: 1px solid #455A64;background-color:#ECEFF1;\">\n",
    "본 자료 및 영상 컨텐츠는 저작권법 제25조 2항에 의해 보호를 받습니다. 본 컨텐츠 및 컨텐츠 일부 문구등을 외부에 공개, 게시하는 것을 금지합니다. 특히 자료에 대해서는 저작권법을 엄격하게 적용하겠습니다.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Get data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!kaggle competitions download -c bike-sharing-demand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. train/test 데이터 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import string\n",
    "import warnings\n",
    "import missingno\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('bikesharing/train.csv')\n",
    "df_test = pd.read_csv('bikesharing/test.csv')\n",
    "df_all = pd.concat((df_train, df_test)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_df(df):\n",
    "    return df[:10885], df[10886:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSLE 기반 예측을 위한 log 필드 추가\n",
    "> RMSLE 가 log 로 계산되므로, 예측값 또한 log 값으로 계산되도록 하는 편이 보다 RMSLE 성능에 도움을 줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['casual_log'] = np.log(df_all['casual'] + 1)\n",
    "df_all['registered_log'] = np.log(df_all['registered'] + 1)\n",
    "df_all['count_log'] = np.log(df_all['count'] + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 시간 필드 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = pd.DatetimeIndex(df_all['datetime'])\n",
    "df_all.set_index(dt, inplace=True)\n",
    "\n",
    "df_all['date'] = dt.date\n",
    "df_all['day'] = dt.day\n",
    "df_all['month'] = dt.month\n",
    "df_all['year'] = dt.year\n",
    "df_all['hour'] = dt.hour\n",
    "df_all['dow'] = dt.dayofweek\n",
    "df_all['woy'] = dt.weekofyear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### peak 타임 필드 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(df_data):\n",
    "    if df_data['workingday'] == 1:\n",
    "        if (df_data['hour'] == 8) or (df_data['hour'] == 17) or (df_data['hour'] == 18):\n",
    "            return 4\n",
    "        elif (df_data['hour'] == 7) or (df_data['hour'] == 16) or (df_data['hour'] == 19): \n",
    "            return 3           \n",
    "    else:\n",
    "        if (df_data['hour'] >= 12 and df_data['hour'] <= 16):\n",
    "            return 2\n",
    "        elif (df_data['hour'] >= 10 and df_data['hour'] <= 19):\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "# 0 or ‘index’: 각 컬럼에 함수 적용, 1 or ‘columns’: 각 행에 함수 적용\n",
    "df_all['peak'] = df_all.apply(func, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(df_data):\n",
    "    # 2021.10.22 업데이트\n",
    "    # 영상에서는 24 일부터 31 일까지를 적용하지만, 테스트 결과 대부분 확실히 쉬는 24일과 31일만 적용했을 때,\n",
    "    # 보다 결과가 좋았기 때문에, 24일과 31일만 적용하였습니다.\n",
    "    if (df_data['month'] == 12) and (df_data['day'] == 24 or df_data['day'] == 31):\n",
    "            return 1\n",
    "    return df_data['holiday']\n",
    "\n",
    "df_all['holiday'] = df_all.apply(func, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(df_data):\n",
    "    # 2021.10.22 업데이트\n",
    "    # 영상에서는 24 일부터 31 일까지를 적용하지만, 테스트 결과 대부분 확실히 쉬는 24일과 31일만 적용했을 때,\n",
    "    # 보다 결과가 좋았기 때문에, 24일과 31일만 적용하였습니다.\n",
    "    if (df_data['month'] == 12) and (df_data['day'] == 24 or df_data['day'] == 31):\n",
    "            return 0\n",
    "    return df_data['workingday']\n",
    "\n",
    "df_all['workingday'] = df_all.apply(func, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 온도, 풍속, 습도, 날씨 기반 fit & humid 필드 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(df_data):\n",
    "    if (df_data['weather'] <= 2 and df_data['windspeed'] <= 20):\n",
    "        if (df_data['temp'] > 15 and df_data['temp'] <= 35):\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "df_all['fit'] = df_all.apply(func, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(df_data):\n",
    "    if df_data['humidity'] >= 70:\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "df_all['humid'] = df_all.apply(func, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ RMSLE = \\sqrt{\\dfrac{\\sum_{i=0}^N (log(y_i + 1) - log(\\hat{y_i} + 1))^2 }{N}} $$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "def get_rmsle(y_actual, y_pred):\n",
    "    diff = np.log(y_pred + 1) - np.log(y_actual + 1)\n",
    "    mean_error = np.square(diff).mean()\n",
    "    return np.sqrt(mean_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation\n",
    "- 참고: np.log() 와 np.exp 는 역함수 \n",
    "- 수학적인 부분보다, 다음과 같이 코드로 바로 이해하기로 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_bikecount(model, select_columns):\n",
    "    df_train, df_test = split_df(df_all)\n",
    "\n",
    "    X_train = df_train[select_columns]\n",
    "    y_train_cas = df_train['casual_log']\n",
    "    y_train_reg = df_train['registered_log']\n",
    "    X_test = df_test[select_columns]\n",
    "    \n",
    "    casual_model = model.fit(X_train, y_train_cas)\n",
    "    y_pred_cas = casual_model.predict(X_test)\n",
    "    y_pred_cas = np.exp(y_pred_cas) - 1\n",
    "\n",
    "    registered_model = model.fit(X_train, y_train_reg)\n",
    "    y_pred_reg = registered_model.predict(X_test)\n",
    "    y_pred_reg = np.exp(y_pred_reg) - 1\n",
    "\n",
    "    return y_pred_cas + y_pred_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation Test: LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = split_df(df_all)\n",
    "ml_columns = [\n",
    "    'season', 'holiday', 'workingday', 'weather', 'temp',\n",
    "    'atemp', 'humidity', 'windspeed', 'day', 'month',\n",
    "    'year', 'hour', 'dow', 'woy', 'peak', 'fit', 'humid'\n",
    "]\n",
    "X_train = df_train[ml_columns].copy()\n",
    "y_train = df_train['count']\n",
    "rmsle_scorer = make_scorer(get_rmsle, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 244k/244k [00:05<00:00, 47.8kB/s]\n",
      "Successfully submitted to Bike Sharing Demand"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr_model = LinearRegression()\n",
    "ml_pred = predict_bikecount(lr_model, ml_columns)\n",
    "df_test['count'] = ml_pred\n",
    "final_df = df_test[['datetime', 'count']].copy()\n",
    "final_df.to_csv('submissions_linear.csv', header=True, index=False)\n",
    "!kaggle competitions submit -c bike-sharing-demand -f submissions_linear.csv -m \"Message\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation Test: Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done 287 tasks      | elapsed:    5.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 10.0, 'max_iter': 1000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 350 out of 350 | elapsed:    6.5s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "hyperparams = {'max_iter': [1000, 1500, 2000, 2500, 3000], \n",
    "               'alpha': 1/np.array([0.1, 1, 2, 3, 4, 10, 30,100,200,300,400,800,900,1000])\n",
    "}\n",
    "\n",
    "lasso_grid=GridSearchCV(estimator = Lasso(), param_grid = hyperparams, \n",
    "                verbose=True, scoring=rmsle_scorer, cv=5, n_jobs=-1)\n",
    "\n",
    "lasso_grid.fit(X_train, y_train)\n",
    "print(lasso_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 240k/240k [00:06<00:00, 38.8kB/s]\n",
      "Successfully submitted to Bike Sharing Demand"
     ]
    }
   ],
   "source": [
    "lasso_model = lasso_grid.best_estimator_\n",
    "ml_pred = predict_bikecount(lasso_model, ml_columns)\n",
    "df_test['count'] = ml_pred\n",
    "final_df = df_test[['datetime', 'count']].copy()\n",
    "final_df.to_csv('submissions_lasso.csv', header=True, index=False)\n",
    "!kaggle competitions submit -c bike-sharing-demand -f submissions_lasso.csv -m \"Message\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation Test: Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 296 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done 350 out of 350 | elapsed:    0.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 1000, 'max_iter': 1000}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "hyperparams = {'max_iter': [1000, 1500, 2000, 2500, 3000], \n",
    "               'alpha':[0.1, 1, 2, 3, 4, 10, 30,100,200,300,400,800,900,1000]\n",
    "}\n",
    "\n",
    "ridge_grid=GridSearchCV(estimator = Ridge(), param_grid = hyperparams, \n",
    "                verbose=True, scoring=rmsle_scorer, cv=5, n_jobs=-1)\n",
    "\n",
    "ridge_grid.fit(X_train, y_train)\n",
    "print(ridge_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 243k/243k [00:04<00:00, 54.6kB/s]\n",
      "Successfully submitted to Bike Sharing Demand"
     ]
    }
   ],
   "source": [
    "ridge_model = ridge_grid.best_estimator_\n",
    "ml_pred = predict_bikecount(ridge_model, ml_columns)\n",
    "df_test['count'] = ml_pred\n",
    "final_df = df_test[['datetime', 'count']].copy()\n",
    "final_df.to_csv('submissions_ridge.csv', header=True, index=False)\n",
    "!kaggle competitions submit -c bike-sharing-demand -f submissions_ridge.csv -m \"Message\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation Test: Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:   44.7s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:  7.8min\n",
      "[Parallel(n_jobs=-1)]: Done 405 out of 405 | elapsed: 19.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 15, 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 1000}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "n_estimators = [800, 1000, 1200]\n",
    "max_depth = [10, 12, 15]\n",
    "min_samples_split = [4, 5, 6]\n",
    "min_samples_leaf = [4, 5, 6]\n",
    "\n",
    "hyperparams = {'n_estimators': n_estimators, 'max_depth': max_depth, \n",
    "               'min_samples_split': min_samples_split, 'min_samples_leaf': min_samples_leaf}\n",
    "\n",
    "rf_grid = GridSearchCV(estimator = RandomForestRegressor(), param_grid = hyperparams, \n",
    "                verbose=True, scoring=rmsle_scorer, cv=5, n_jobs=-1)\n",
    "\n",
    "rf_grid.fit(X_train, y_train)\n",
    "print(rf_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 243k/243k [00:06<00:00, 38.7kB/s]\n",
      "Successfully submitted to Bike Sharing Demand"
     ]
    }
   ],
   "source": [
    "rf_model = rf_grid.best_estimator_\n",
    "ml_pred = predict_bikecount(rf_model, ml_columns)\n",
    "df_test['count'] = ml_pred\n",
    "final_df = df_test[['datetime', 'count']].copy()\n",
    "final_df.to_csv('submissions_rf.csv', header=True, index=False)\n",
    "!kaggle competitions submit -c bike-sharing-demand -f submissions_rf.csv -m \"Message\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation Test: XGBoost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:   11.1s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 418 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 720 out of 720 | elapsed:  6.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 5, 'min_child_weight': 5, 'n_estimators': 250, 'nthread': 4, 'subsample': 0.7}\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor # 회귀트리 모델\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "hyperparams = {'nthread':[4],\n",
    "              'learning_rate': [0.05, 0.1, 0.15], \n",
    "              'max_depth': [4, 5],\n",
    "              'min_child_weight': [3, 4, 5],\n",
    "              'subsample': [0.7, 0.8],\n",
    "              'colsample_bytree': [0.6, 0.7],\n",
    "              'n_estimators': [250, 500]}\n",
    "\n",
    "xgb_grid = GridSearchCV(estimator = XGBRegressor(), param_grid = hyperparams, \n",
    "                verbose=True, scoring=rmsle_scorer, cv=5, n_jobs=-1)\n",
    "\n",
    "xgb_grid.fit(X_train, y_train)\n",
    "print(xgb_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 188k/188k [00:05<00:00, 36.4kB/s]\n",
      "Successfully submitted to Bike Sharing Demand"
     ]
    }
   ],
   "source": [
    "xgb_model = xgb_grid.best_estimator_\n",
    "ml_pred = predict_bikecount(xgb_model, X_train.columns)\n",
    "df_test['count'] = ml_pred\n",
    "final_df = df_test[['datetime', 'count']].copy()\n",
    "final_df.to_csv('submissions_xgboost.csv', header=True, index=False)\n",
    "!kaggle competitions submit -c bike-sharing-demand -f submissions_xgboost.csv -m \"Message\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation Test: Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 243 candidates, totalling 1215 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:   41.8s\n",
      "[Parallel(n_jobs=-1)]: Done 418 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 768 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1215 out of 1215 | elapsed:  5.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.1, 'max_depth': 7, 'min_samples_leaf': 8, 'n_estimators': 100, 'subsample': 0.7}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "n_estimators = [100, 150, 200]\n",
    "max_depth = [5, 7, 9]\n",
    "min_samples_leaf = [8, 10, 12]\n",
    "learning_rate = [0.1, 0.15, 0.2]\n",
    "subsample = [0.6, 0.7, 0.8]\n",
    "\n",
    "hyperparams = {'n_estimators': n_estimators, 'max_depth': max_depth, \n",
    "                    'min_samples_leaf': min_samples_leaf,\n",
    "                    'learning_rate': learning_rate, 'subsample': subsample\n",
    "              }\n",
    "\n",
    "gb_grid=GridSearchCV(estimator = GradientBoostingRegressor(), param_grid = hyperparams, \n",
    "                verbose=True, scoring=rmsle_scorer, cv=5, n_jobs=-1)\n",
    "\n",
    "gb_grid.fit(X_train, y_train)\n",
    "print(gb_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 243k/243k [00:04<00:00, 50.8kB/s]\n",
      "Successfully submitted to Bike Sharing Demand"
     ]
    }
   ],
   "source": [
    "gb_model = gb_grid.best_estimator_\n",
    "ml_pred = predict_bikecount(gb_model, X_train.columns)\n",
    "df_test['count'] = ml_pred\n",
    "final_df = df_test[['datetime', 'count']].copy()\n",
    "final_df.to_csv('submissions_gb.csv', header=True, index=False)\n",
    "!kaggle competitions submit -c bike-sharing-demand -f submissions_gb.csv -m \"Message\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block\" style=\"border: 1px solid #455A64;background-color:#ECEFF1;\">\n",
    "본 자료 및 영상 컨텐츠는 저작권법 제25조 2항에 의해 보호를 받습니다. 본 컨텐츠 및 컨텐츠 일부 문구등을 외부에 공개, 게시하는 것을 금지합니다. 특히 자료에 대해서는 저작권법을 엄격하게 적용하겠습니다.\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
