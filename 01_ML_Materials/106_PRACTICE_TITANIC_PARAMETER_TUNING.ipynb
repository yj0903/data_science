{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block\" style=\"border: 1px solid #455A64;background-color:#ECEFF1;\">\n",
    "본 자료 및 영상 컨텐츠는 저작권법 제25조 2항에 의해 보호를 받습니다. 본 컨텐츠 및 컨텐츠 일부 문구등을 외부에 공개, 게시하는 것을 금지합니다. 특히 자료에 대해서는 저작권법을 엄격하게 적용하겠습니다.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 준비 작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "with open('titanic_step4_importance_train.pickle', 'rb') as pickle_filename:\n",
    "    # 202402 업데이트: pandas 2.0.3 버전 이상에서는 pickle.load 실행시 에러가 남\n",
    "    # 대신에 pd.read_pickle() 호출하면 됨\n",
    "    # train_importance = pickle.load(pickle_filename)    \n",
    "    train_importance = pd.read_pickle(pickle_filename)\n",
    "with open('titanic_step4_importance_test.pickle', 'rb') as pickle_filename:\n",
    "    # 202402 업데이트: pandas 2.0.3 버전 이상에서는 pickle.load 실행시 에러가 남\n",
    "    # 대신에 pd.read_pickle() 호출하면 됨\n",
    "    # test_importance = pickle.load(pickle_filename)    \n",
    "    test_importance = pd.read_pickle(pickle_filename)\n",
    "with open('titanic_step4_importance_train_y.pickle', 'rb') as pickle_filename:\n",
    "    # 202402 업데이트: pandas 2.0.3 버전 이상에서는 pickle.load 실행시 에러가 남\n",
    "    # 대신에 pd.read_pickle() 호출하면 됨\n",
    "    # train_answer = pickle.load(pickle_filename)    \n",
    "    train_answer = pd.read_pickle(pickle_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 주요 라이브러리 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np # 각 모델에서 내부적으로 관련 라이브러리 사용 가능\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier             # 1. K-Nearest Neighbor(KNN)\n",
    "from sklearn.linear_model import LogisticRegression            # 2. Logistic Regression\n",
    "from sklearn.svm import SVC                                                # 3. SVC\n",
    "from sklearn.tree import DecisionTreeClassifier                   # 4. Decision Tree\n",
    "from sklearn.ensemble import RandomForestClassifier       # 5. Random Forest\n",
    "from sklearn.ensemble import ExtraTreesClassifier             # 6. Extra Tree\n",
    "from sklearn.ensemble import GradientBoostingClassifier  # 7. GBM\n",
    "from sklearn.naive_bayes import GaussianNB                     # 8. GaussianNB\n",
    "from xgboost import XGBClassifier                                     # 9. XGBoost\n",
    "from lightgbm import LGBMClassifier                                 # 10. LightGBM\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 하이퍼 파라미터 튜닝과 SVC\n",
    "- SVC 는 결국 분류의 경계가 되는 경계선을 작성하여, 분류를 실행하는 모델\n",
    "- 해당 경계선을 일직선으로 할지, 어느 정도 곡률을 가진 선으로 할지도 선정 가능\n",
    "- 주요 하이퍼 파라미터\n",
    "  - C : regularization 파라미터\n",
    "  - gamma: 어느 정도 훈련 셋에 fit 하게 할지를 결정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomizedSearchCV + SVC\n",
    "- RandomizedSearchCV() 는 랜덤하게 파라미터값을 선정하여, 테스트를 수행하므로,\n",
    "- 보다 적합한 파라미터값을 도출하기 위해서는 수행횟수를 늘려야 함\n",
    "- 따라서 머신러닝 모델의 수행성능에 따라, RandomizedSearchCV() 사용시, 수행시간이 상당히 오래 걸릴 수 있으므로,\n",
    "- RandomizedSearchCV() 이해를 위해서만 일부 모델에서만 테스트를 진행하고,\n",
    "- GridSearchCV() 을 주로 사용하기로 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 참고: 균일 분포 또는 균등 분포(Uniform Distribution)\n",
    "  - 정해진 범위에서 모든 확률이 균일한 분포를 의미함\n",
    "  - 균일 분포는 이산형 확률 분포와 연속형 확률 분포 두 형태가 존재 \n",
    "  - 연속형 확률 분포: 두 점 a,b 사이의 연속적인 값에 대한 확률 분포\n",
    "  - 이산형 확률 분포: 두 점 a,b 사이에 갯수가 정해진 값들에 대한 확률 분포"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stats.uniform(loc, scale)\n",
    "- loc 부터, loc + scale 까지의 범위에서 균등한 확률로 연속형 값을 추출\n",
    "- 해당 객체는 rvs() 메서드를 가지고 있고, 이를 사용해서, RandomizedSearchCV() 가 랜덤 값을 균등 확률로 추출해서, 적용 및 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8372920720607621\n",
      "{'C': 7.337794540855652, 'gamma': 0.0923385947687978}\n",
      "                                               params  mean_test_score\n",
      "0   {'C': 20.8511002351287, 'gamma': 0.72032449344...         0.822717\n",
      "1   {'C': 0.005718740867244332, 'gamma': 0.3023325...         0.616163\n",
      "2   {'C': 7.337794540855652, 'gamma': 0.0923385947...         0.837292\n",
      "3   {'C': 9.313010568883545, 'gamma': 0.3455607270...         0.823809\n",
      "4   {'C': 19.838373711533496, 'gamma': 0.538816734...         0.823821\n",
      "..                                                ...              ...\n",
      "95  {'C': 13.164838524355549, 'gamma': 0.065961090...         0.832804\n",
      "96  {'C': 36.753298164433474, 'gamma': 0.772178029...         0.818235\n",
      "97  {'C': 45.3907926251762, 'gamma': 0.93197206919...         0.812623\n",
      "98  {'C': 0.6975786487798508, 'gamma': 0.234362086...         0.835013\n",
      "99  {'C': 30.83891785008288, 'gamma': 0.9490163206...         0.811506\n",
      "\n",
      "[100 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "hyperparams = {\n",
    "    \"C\": stats.uniform(0, 50),\n",
    "    \"gamma\": stats.uniform(0, 1)\n",
    "}\n",
    "gd = RandomizedSearchCV(\n",
    "    estimator = SVC(random_state=1), \n",
    "    param_distributions=hyperparams, \n",
    "    n_iter=100, \n",
    "    cv=5,   # 내부적으로 (Stratified)KFold 사용\n",
    "    scoring='accuracy', \n",
    "    random_state=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "# 2022.12.22 해당 라이브러리 변경으로 인터페이스가 변경되어,  기존 코드로 경고표시가 나옵니다.\n",
    "#  경고표시가 나오더라도, 진행에는 문제가 없지만, 당황하실 수 있어서, 경고표시가 나오지 않도록 코드를 업데이트합니다.\n",
    "# gd.fit(train_importance, train_answer) \n",
    "gd.fit(train_importance, train_answer.values.ravel())\n",
    "\n",
    "print(gd.best_score_)\n",
    "print(gd.best_params_)\n",
    "\n",
    "df = pd.DataFrame(gd.cv_results_)\n",
    "print(df[['params','mean_test_score']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC + 하이퍼 파라미터 튜닝 (GridSearchCV 사용)\n",
    "> 하이퍼파라미터는 일반적으로 적절한 범위가 없기 때문에, 각 데이터에 맞춰서 성능이 나오는 범위를 감으로 지정해야 함\n",
    "> RandomizedSearchCV() 를 통해, 대략적인 범위를 알아낸 후, 이를 기반으로 GridSearchCV() 를 사용하여\n",
    "> 범위와, 최적의 값을 가질 수 있는 후보군을 지정하는 방식으로, 최적의 하이퍼파라미터 값을 찾아가는 방법을 많이 사용함 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 42 candidates, totalling 210 fits\n",
      "0.8395016006528152\n",
      "{'C': 50, 'gamma': 0.01}\n"
     ]
    }
   ],
   "source": [
    "# 파라미터 그리드 셋팅\n",
    "hyperparams = {\n",
    "    'C': [10, 15, 20, 23, 25, 30, 50], \n",
    "    'gamma' : [0.001, 0.01, 0.05, 0.06, 0.07, 0.1]\n",
    "}\n",
    "\n",
    "# 교차검증\n",
    "gd=GridSearchCV(\n",
    "    estimator = SVC(random_state=1), \n",
    "    param_grid = hyperparams, \n",
    "    verbose=True, \n",
    "    cv=5,   # 내부적으로 (Stratified)KFold 사용\n",
    "    scoring = \"accuracy\", \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# 2022.12.22 해당 라이브러리 변경으로 인터페이스가 변경되어,  기존 코드로 경고표시가 나옵니다.\n",
    "#  경고표시가 나오더라도, 진행에는 문제가 없지만, 당황하실 수 있어서, 경고표시가 나오지 않도록 코드를 업데이트합니다.\n",
    "# gd.fit(train_importance, train_answer) \n",
    "gd.fit(train_importance, train_answer.values.ravel())\n",
    "print(gd.best_score_)\n",
    "print(gd.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block\" style=\"border: 2px solid #E65100;background-color:#FFF3E0;padding:10px\">\n",
    "<font size=\"4em\" style=\"font-weight:bold;color:#BF360C;\">큰그림으로 이해하기</font><br>\n",
    "<font size=\"4em\" style=\"color:#BF360C;\">데이터를 어떻게 짜르느냐에 따라, 예측 성능은 다르게 계산될 수 있지만,</font><br>\n",
    "<font size=\"4em\" style=\"color:#BF360C;\">동일한 테스트 환경에서, 하이퍼파라미터 튜닝 전 보다, PC에 따라 다르겠지만, 다소 예측 정확도가 올라감</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Gradient Boosting Classifier 주요 하이퍼 파라미터\n",
    "- learning_rate는 학습률을 의미하며, 각 트리의 오류에 기반해서, 어느 정도 수정할지의 비율을 의미\n",
    "- n_estimator 는 트리의 갯수를 의미\n",
    "- max_depth 는 트리의 깊이를 의미"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Classifier + 하이퍼 파라미터 튜닝 (GridSearchCV 사용)\n",
    "- Gradient Boosting Classifier 는 수행시간이 오래 걸리므로, RandomizedSearchCV() 로 사전 테스트를 통해, 대략적인 최적의 파라미터값을 예상하여, GridSearchCV() 로 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "0.8406440273680245\n",
      "{'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "learning_rate = [0.01, 0.05, 0.1, 0.2]\n",
    "n_estimators = [100, 1000, 2000]\n",
    "max_depth = [3, 5, 10, 15]\n",
    "\n",
    "hyperparams = {\n",
    "    'learning_rate': learning_rate, \n",
    "    'n_estimators': n_estimators, \n",
    "    'max_depth': max_depth\n",
    "}\n",
    "\n",
    "gd=GridSearchCV(\n",
    "    estimator = GradientBoostingClassifier(random_state=1), \n",
    "    param_grid = hyperparams, \n",
    "    verbose=True, \n",
    "    cv=5, \n",
    "    scoring = \"accuracy\", \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# 2022.12.22 해당 라이브러리 변경으로 인터페이스가 변경되어,  기존 코드로 경고표시가 나옵니다.\n",
    "#  경고표시가 나오더라도, 진행에는 문제가 없지만, 당황하실 수 있어서, 경고표시가 나오지 않도록 코드를 업데이트합니다.\n",
    "# gd.fit(train_importance, train_answer) \n",
    "gd.fit(train_importance, train_answer.values.ravel())\n",
    "print(gd.best_score_)\n",
    "print(gd.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block\" style=\"border: 2px solid #E65100;background-color:#FFF3E0;padding:10px\">\n",
    "<font size=\"4em\" style=\"font-weight:bold;color:#BF360C;\">큰그림으로 이해하기</font><br>\n",
    "<font size=\"4em\" style=\"color:#BF360C;\">데이터를 어떻게 짜르느냐에 따라, 예측 성능은 다르게 계산될 수 있지만,</font><br>\n",
    "<font size=\"4em\" style=\"color:#BF360C;\">동일한 테스트 환경에서, 하이퍼파라미터 튜닝 전 보다, 성능이 개선됨</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Logistic Regression 주요 하이퍼 파라미터\n",
    "* penalty: regularization 종류 선정 (l1, l2 등)\n",
    "* C: regularization 적용 강도"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression + 하이퍼 파라미터 튜닝 (RandomizedSearchCV 사용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8395455401418618\n",
      "{'C': 29.801358182393265, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "# 본 코드는 컴퓨터 성능에 따라 수행시간이 매우 오래 걸리고, 수행시간 제한으로 주피터 노트북등이 다운될 수도 있음\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "hyperparams = {\n",
    "    'penalty': ['l1', 'l2', 'elasticnet'], \n",
    "    'C': stats.uniform(0, 1000)\n",
    "}\n",
    "gd = RandomizedSearchCV(\n",
    "    # 2022.12.22 해당 라이브러리 변경으로 인터페이스가 변경되어,  기존 코드로 경고표시가 나옵니다.\n",
    "    #  경고표시가 나오더라도, 진행에는 문제가 없지만, 당황하실 수 있어서, 경고표시가 나오지 않도록 코드를 업데이트합니다.\n",
    "    # estimator = LogisticRegression(random_state=1)\n",
    "    estimator = LogisticRegression(random_state=1, solver='lbfgs', max_iter=1000), \n",
    "    param_distributions=hyperparams, \n",
    "    n_iter=100, \n",
    "    cv=5, \n",
    "    scoring='accuracy', \n",
    "    random_state=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "# 2022.12.22 해당 라이브러리 변경으로 인터페이스가 변경되어,  기존 코드로 경고표시가 나옵니다.\n",
    "#  경고표시가 나오더라도, 진행에는 문제가 없지만, 당황하실 수 있어서, 경고표시가 나오지 않도록 코드를 업데이트합니다.\n",
    "# gd.fit(train_importance, train_answer) \n",
    "gd.fit(train_importance, train_answer.values.ravel())\n",
    "print(gd.best_score_)\n",
    "print(gd.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression + 하이퍼 파라미터 튜닝 (GridSearchCV 사용)\n",
    "- numpy.linspace(start, end, num)\n",
    "  - start ~ end 사이의 값을 등간격으로 num 갯수만큼의 배열을 생성하는 numpy 메서드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([700.        , 722.22222222, 744.44444444, 766.66666667,\n",
       "       788.88888889, 811.11111111, 833.33333333, 855.55555556,\n",
       "       877.77777778, 900.        ])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(700, 900, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 400 candidates, totalling 2000 fits\n",
      "0.83841566756638\n",
      "{'C': 702.0100502512563, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "penalty = ['l1', 'l2']\n",
    "C = np.linspace(700, 900, 200)\n",
    "\n",
    "hyperparams = {\n",
    "    'penalty': penalty, \n",
    "    'C': C\n",
    "}\n",
    "\n",
    "gd=GridSearchCV(\n",
    "    # 2022.12.22 해당 라이브러리 변경으로 인터페이스가 변경되어,  기존 코드로 경고표시가 나옵니다.\n",
    "    #  경고표시가 나오더라도, 진행에는 문제가 없지만, 당황하실 수 있어서, 경고표시가 나오지 않도록 코드를 업데이트합니다.\n",
    "    # estimator = LogisticRegression(random_state=1)\n",
    "    estimator = LogisticRegression(random_state=1, solver='lbfgs', max_iter=1000), \n",
    "    param_grid = hyperparams, \n",
    "    verbose=True, \n",
    "    cv=5, \n",
    "    scoring = \"accuracy\", \n",
    "    n_jobs=-1\n",
    ")\n",
    "# 2022.12.22 해당 라이브러리 변경으로 인터페이스가 변경되어,  기존 코드로 경고표시가 나옵니다.\n",
    "#  경고표시가 나오더라도, 진행에는 문제가 없지만, 당황하실 수 있어서, 경고표시가 나오지 않도록 코드를 업데이트합니다.\n",
    "# gd.fit(train_importance, train_answer) \n",
    "gd.fit(train_importance, train_answer.values.ravel())\n",
    "print(gd.best_score_)\n",
    "print(gd.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block\" style=\"border: 2px solid #E65100;background-color:#FFF3E0;padding:10px\">\n",
    "<font size=\"4em\" style=\"font-weight:bold;color:#BF360C;\">큰그림으로 이해하기</font><br>\n",
    "<font size=\"4em\" style=\"color:#BF360C;\">데이터를 어떻게 짜르느냐에 따라, 예측 성능은 다르게 계산될 수 있으며,</font><br>\n",
    "<font size=\"4em\" style=\"color:#BF360C;\">동일한 테스트 환경에서, 하이퍼파라미터 튜닝 전 보다는 정확도가 올라감</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. XGBoost 와 주요 하이퍼 파라미터\n",
    "- 일반적인 XGBoost 하이퍼 파라미터 튜닝 전략\n",
    "   - ensemble 방식은 수행시, 각 파라미터를 적절히 맞춰주기 때문에, 하이퍼 파라미터 튜닝이 정확도를 높이는데 있어서, 큰 기여를 하는 편은 아니며, \n",
    "   - 무수히 많은 파라미터가 있고, 수행 시간이 오래 걸리므로, 주요한 파라미터들만 중심으로 튜닝을 진행하는 편이 좋음\n",
    "- 성능에 영향을 많이 끼치는 주요 파라미터\n",
    "   - learning_rate \n",
    "      - 이전 결과를 얼마나 반영할지에 대한 학습 단계별 적용할 가중치를 의미함 \n",
    "      - 일반적으로 0.01 ~ 0.2 사이의 값을 많이 사용함\n",
    "   - max_depth\n",
    "      - 트리의 최대 깊이를 의미함\n",
    "      - 트리의 최대 깊이로 -1 로 하면, 깊이에 제한을 두지 않음 \n",
    "      - 일반적으로 3 ~ 10 사이의 값을 많이 사용함\n",
    "   - gamma\n",
    "      - 일종의 정규화(regularization) 파라미터로, gamma 가 높을 수록, regularization 이 높다고 이해하면 됨\n",
    "      - 트리에서 가지를 추가로 만들기 위해 필요한 최소 loss 기준값으로, gamma 값이 작으면, 트리에 보다 많은 가지가 만들어진다고 이해하면 됨\n",
    "      - 일반적으로 0 이상의 값을 가짐\n",
    "   - min_child_weight\n",
    "      - 트리에서 가지를 추가로 만들어 분할하기 위해, 필요한 최소한의 샘플 수\n",
    "      - 값이 적을 수록, 트리가 더 분할될 수 있음\n",
    "      - 일반적으로 0 이상의 값을 가짐\n",
    "   - subsample\n",
    "      - 각 트리마다 모든 훈련데이터를 사용해서 트리를 만들지 않음\n",
    "      - 훈련 데이터의 일부를 사용해서 트리를 만든다면, 보다 많은 트리를 만들 수 있고, 이를 통해 트리의 다양성을 높일 수 있음\n",
    "      - subsample 은 이 때, 각 트리마다 어느 정도의 훈련 데이터 비율을 사용해서 트리를 만들지를 그 비율을 정하는 것임\n",
    "      - 일반적으로 0.5 ~ 1 사이의 값을 많이 사용함\n",
    "   - colsample_bytree\n",
    "      - subsample 과 마찬가지로, 훈련 데이터에서 일부 feature (컬럼) 들만 뽑아서 트리를 만드는 방식\n",
    "      - 일부 feature (컬럼)들만 뽑아서 트리를 만든다면, 보다 많은 트리를 만들 수 있고, 이를 통해 트리의 다양성을 높일 수 있음\n",
    "      - colsample_bytree 는 이를 위해 각 트리를 만들 때 사용할 feature의 비율을 정하는 것임\n",
    "      - 일반적으로 0.5 ~ 1 사이의 값을 많이 사용함\n",
    "      \n",
    "   - reg_alpha: L1 정규화(regularization) 가중치\n",
    "   - reg_lambda: L2 정규화(regularization) 가중치"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian Optimization 를 위한 파이썬 라이브러리 설치\n",
    "<div class=\"alert alert-block\" style=\"border: 2px solid #E65100;background-color:#FFF3E0;padding:10px\">\n",
    "<font size=\"4em\" style=\"font-weight:bold;color:#BF360C;\">2022.12.22 업데이트</font><br>\n",
    "<font size=\"4em\" style=\"color:#BF360C;\">라이브러리가 업데이트되었으나, 버그가 있어서, 에러가 발생하고 있습니다.</font><br>\n",
    "<font size=\"4em\" style=\"color:#BF360C;\">따라서, 라이브러리 버전을 기존 버전으로 고정하였습니다</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bayesian-optimization==1.4.3 in /Users/davelee/opt_new/anaconda3/lib/python3.11/site-packages (1.4.3)\r\n",
      "Requirement already satisfied: numpy>=1.9.0 in /Users/davelee/opt_new/anaconda3/lib/python3.11/site-packages (from bayesian-optimization==1.4.3) (1.24.3)\r\n",
      "Requirement already satisfied: scipy>=1.0.0 in /Users/davelee/opt_new/anaconda3/lib/python3.11/site-packages (from bayesian-optimization==1.4.3) (1.11.1)\r\n",
      "Requirement already satisfied: scikit-learn>=0.18.0 in /Users/davelee/opt_new/anaconda3/lib/python3.11/site-packages (from bayesian-optimization==1.4.3) (1.3.0)\r\n",
      "Requirement already satisfied: colorama>=0.4.6 in /Users/davelee/opt_new/anaconda3/lib/python3.11/site-packages (from bayesian-optimization==1.4.3) (0.4.6)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/davelee/opt_new/anaconda3/lib/python3.11/site-packages (from scikit-learn>=0.18.0->bayesian-optimization==1.4.3) (1.2.0)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/davelee/opt_new/anaconda3/lib/python3.11/site-packages (from scikit-learn>=0.18.0->bayesian-optimization==1.4.3) (2.2.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install bayesian-optimization==1.4.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian Optimization XGBoost 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... |   gamma   | learni... | max_depth | min_ch... | n_esti... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m0.8137   \u001b[0m | \u001b[0m0.7085   \u001b[0m | \u001b[0m3.602    \u001b[0m | \u001b[0m0.01006  \u001b[0m | \u001b[0m5.116    \u001b[0m | \u001b[0m1.468    \u001b[0m | \u001b[0m183.1    \u001b[0m | \u001b[0m0.5931   \u001b[0m |\n",
      "| \u001b[95m2        \u001b[0m | \u001b[95m0.8227   \u001b[0m | \u001b[95m0.6728   \u001b[0m | \u001b[95m1.984    \u001b[0m | \u001b[95m0.274    \u001b[0m | \u001b[95m5.934    \u001b[0m | \u001b[95m6.852    \u001b[0m | \u001b[95m284.0    \u001b[0m | \u001b[95m0.9391   \u001b[0m |\n",
      "| \u001b[95m3        \u001b[0m | \u001b[95m0.8283   \u001b[0m | \u001b[95m0.5137   \u001b[0m | \u001b[95m3.352    \u001b[0m | \u001b[95m0.2145   \u001b[0m | \u001b[95m6.911    \u001b[0m | \u001b[95m1.404    \u001b[0m | \u001b[95m278.3    \u001b[0m | \u001b[95m0.9004   \u001b[0m |\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m0.8014   \u001b[0m | \u001b[0m0.9841   \u001b[0m | \u001b[0m1.567    \u001b[0m | \u001b[0m0.3492   \u001b[0m | \u001b[0m9.135    \u001b[0m | \u001b[0m8.946    \u001b[0m | \u001b[0m176.5    \u001b[0m | \u001b[0m0.5195   \u001b[0m |\n",
      "| \u001b[0m5        \u001b[0m | \u001b[0m0.8025   \u001b[0m | \u001b[0m0.5849   \u001b[0m | \u001b[0m4.391    \u001b[0m | \u001b[0m0.05819  \u001b[0m | \u001b[0m5.948    \u001b[0m | \u001b[0m9.579    \u001b[0m | \u001b[0m579.8    \u001b[0m | \u001b[0m0.8459   \u001b[0m |\n",
      "| \u001b[0m6        \u001b[0m | \u001b[0m0.8216   \u001b[0m | \u001b[0m0.6578   \u001b[0m | \u001b[0m3.433    \u001b[0m | \u001b[0m0.419    \u001b[0m | \u001b[0m3.128    \u001b[0m | \u001b[0m7.501    \u001b[0m | \u001b[0m990.0    \u001b[0m | \u001b[0m0.8741   \u001b[0m |\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m0.798    \u001b[0m | \u001b[0m0.6402   \u001b[0m | \u001b[0m3.946    \u001b[0m | \u001b[0m0.06058  \u001b[0m | \u001b[0m6.135    \u001b[0m | \u001b[0m9.086    \u001b[0m | \u001b[0m364.3    \u001b[0m | \u001b[0m0.6439   \u001b[0m |\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m0.8216   \u001b[0m | \u001b[0m0.565    \u001b[0m | \u001b[0m0.09683  \u001b[0m | \u001b[0m0.3426   \u001b[0m | \u001b[0m4.481    \u001b[0m | \u001b[0m2.655    \u001b[0m | \u001b[0m542.4    \u001b[0m | \u001b[0m0.5267   \u001b[0m |\n",
      "| \u001b[95m9        \u001b[0m | \u001b[95m0.8373   \u001b[0m | \u001b[95m0.7871   \u001b[0m | \u001b[95m0.7336   \u001b[0m | \u001b[95m0.2988   \u001b[0m | \u001b[95m7.898    \u001b[0m | \u001b[95m1.023    \u001b[0m | \u001b[95m472.7    \u001b[0m | \u001b[95m0.8472   \u001b[0m |\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m0.8216   \u001b[0m | \u001b[0m0.7071   \u001b[0m | \u001b[0m0.2498   \u001b[0m | \u001b[0m0.2726   \u001b[0m | \u001b[0m7.647    \u001b[0m | \u001b[0m5.149    \u001b[0m | \u001b[0m950.1    \u001b[0m | \u001b[0m0.7933   \u001b[0m |\n",
      "| \u001b[0m11       \u001b[0m | \u001b[0m0.8361   \u001b[0m | \u001b[0m0.5523   \u001b[0m | \u001b[0m1.118    \u001b[0m | \u001b[0m0.02605  \u001b[0m | \u001b[0m7.734    \u001b[0m | \u001b[0m2.317    \u001b[0m | \u001b[0m472.2    \u001b[0m | \u001b[0m0.5697   \u001b[0m |\n",
      "| \u001b[0m12       \u001b[0m | \u001b[0m0.8227   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.5      \u001b[0m | \u001b[0m10.0     \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m490.1    \u001b[0m | \u001b[0m1.0      \u001b[0m |\n",
      "| \u001b[0m13       \u001b[0m | \u001b[0m0.8249   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.5      \u001b[0m | \u001b[0m10.0     \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m457.2    \u001b[0m | \u001b[0m1.0      \u001b[0m |\n",
      "| \u001b[0m14       \u001b[0m | \u001b[0m0.8182   \u001b[0m | \u001b[0m0.9764   \u001b[0m | \u001b[0m4.534    \u001b[0m | \u001b[0m0.4275   \u001b[0m | \u001b[0m8.831    \u001b[0m | \u001b[0m0.08152  \u001b[0m | \u001b[0m256.9    \u001b[0m | \u001b[0m0.9497   \u001b[0m |\n",
      "| \u001b[0m15       \u001b[0m | \u001b[0m0.8013   \u001b[0m | \u001b[0m0.6155   \u001b[0m | \u001b[0m3.534    \u001b[0m | \u001b[0m0.02947  \u001b[0m | \u001b[0m8.389    \u001b[0m | \u001b[0m9.974    \u001b[0m | \u001b[0m917.1    \u001b[0m | \u001b[0m0.5158   \u001b[0m |\n",
      "| \u001b[0m16       \u001b[0m | \u001b[0m0.8193   \u001b[0m | \u001b[0m0.889    \u001b[0m | \u001b[0m3.877    \u001b[0m | \u001b[0m0.04379  \u001b[0m | \u001b[0m3.152    \u001b[0m | \u001b[0m0.5503   \u001b[0m | \u001b[0m476.0    \u001b[0m | \u001b[0m0.8602   \u001b[0m |\n",
      "| \u001b[0m17       \u001b[0m | \u001b[0m0.8204   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.5      \u001b[0m | \u001b[0m10.0     \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m467.2    \u001b[0m | \u001b[0m1.0      \u001b[0m |\n",
      "| \u001b[0m18       \u001b[0m | \u001b[0m0.8216   \u001b[0m | \u001b[0m0.8918   \u001b[0m | \u001b[0m0.3236   \u001b[0m | \u001b[0m0.46     \u001b[0m | \u001b[0m8.992    \u001b[0m | \u001b[0m5.245    \u001b[0m | \u001b[0m475.6    \u001b[0m | \u001b[0m0.7204   \u001b[0m |\n",
      "| \u001b[0m19       \u001b[0m | \u001b[0m0.8361   \u001b[0m | \u001b[0m0.7475   \u001b[0m | \u001b[0m1.062    \u001b[0m | \u001b[0m0.1342   \u001b[0m | \u001b[0m3.972    \u001b[0m | \u001b[0m0.1936   \u001b[0m | \u001b[0m469.4    \u001b[0m | \u001b[0m0.6763   \u001b[0m |\n",
      "| \u001b[0m20       \u001b[0m | \u001b[0m0.835    \u001b[0m | \u001b[0m0.6692   \u001b[0m | \u001b[0m0.5037   \u001b[0m | \u001b[0m0.4006   \u001b[0m | \u001b[0m3.351    \u001b[0m | \u001b[0m5.193    \u001b[0m | \u001b[0m467.9    \u001b[0m | \u001b[0m0.6572   \u001b[0m |\n",
      "| \u001b[0m21       \u001b[0m | \u001b[0m0.8081   \u001b[0m | \u001b[0m0.609    \u001b[0m | \u001b[0m4.791    \u001b[0m | \u001b[0m0.08724  \u001b[0m | \u001b[0m4.095    \u001b[0m | \u001b[0m5.944    \u001b[0m | \u001b[0m464.1    \u001b[0m | \u001b[0m0.6903   \u001b[0m |\n",
      "| \u001b[0m22       \u001b[0m | \u001b[0m0.8272   \u001b[0m | \u001b[0m0.5553   \u001b[0m | \u001b[0m0.5365   \u001b[0m | \u001b[0m0.2805   \u001b[0m | \u001b[0m4.636    \u001b[0m | \u001b[0m2.59     \u001b[0m | \u001b[0m473.6    \u001b[0m | \u001b[0m0.8349   \u001b[0m |\n",
      "| \u001b[0m23       \u001b[0m | \u001b[0m0.8283   \u001b[0m | \u001b[0m0.8651   \u001b[0m | \u001b[0m4.417    \u001b[0m | \u001b[0m0.3429   \u001b[0m | \u001b[0m9.328    \u001b[0m | \u001b[0m0.09387  \u001b[0m | \u001b[0m472.2    \u001b[0m | \u001b[0m0.72     \u001b[0m |\n",
      "| \u001b[0m24       \u001b[0m | \u001b[0m0.835    \u001b[0m | \u001b[0m0.5      \u001b[0m | \u001b[0m1.092    \u001b[0m | \u001b[0m0.2929   \u001b[0m | \u001b[0m8.33     \u001b[0m | \u001b[0m6.267    \u001b[0m | \u001b[0m273.8    \u001b[0m | \u001b[0m0.9206   \u001b[0m |\n",
      "| \u001b[0m25       \u001b[0m | \u001b[0m0.8204   \u001b[0m | \u001b[0m0.7542   \u001b[0m | \u001b[0m3.301    \u001b[0m | \u001b[0m0.4203   \u001b[0m | \u001b[0m3.627    \u001b[0m | \u001b[0m6.048    \u001b[0m | \u001b[0m272.2    \u001b[0m | \u001b[0m0.5969   \u001b[0m |\n",
      "| \u001b[0m26       \u001b[0m | \u001b[0m0.816    \u001b[0m | \u001b[0m0.6702   \u001b[0m | \u001b[0m3.983    \u001b[0m | \u001b[0m0.1235   \u001b[0m | \u001b[0m9.55     \u001b[0m | \u001b[0m7.821    \u001b[0m | \u001b[0m276.9    \u001b[0m | \u001b[0m0.795    \u001b[0m |\n",
      "| \u001b[0m27       \u001b[0m | \u001b[0m0.8283   \u001b[0m | \u001b[0m0.8321   \u001b[0m | \u001b[0m0.6592   \u001b[0m | \u001b[0m0.2186   \u001b[0m | \u001b[0m8.299    \u001b[0m | \u001b[0m2.182    \u001b[0m | \u001b[0m271.7    \u001b[0m | \u001b[0m0.9646   \u001b[0m |\n",
      "| \u001b[0m28       \u001b[0m | \u001b[0m0.825    \u001b[0m | \u001b[0m0.6031   \u001b[0m | \u001b[0m0.4997   \u001b[0m | \u001b[0m0.3163   \u001b[0m | \u001b[0m8.889    \u001b[0m | \u001b[0m8.247    \u001b[0m | \u001b[0m270.5    \u001b[0m | \u001b[0m0.6953   \u001b[0m |\n",
      "| \u001b[0m29       \u001b[0m | \u001b[0m0.8362   \u001b[0m | \u001b[0m0.604    \u001b[0m | \u001b[0m2.609    \u001b[0m | \u001b[0m0.479    \u001b[0m | \u001b[0m5.312    \u001b[0m | \u001b[0m2.997    \u001b[0m | \u001b[0m470.0    \u001b[0m | \u001b[0m0.857    \u001b[0m |\n",
      "| \u001b[0m30       \u001b[0m | \u001b[0m0.8126   \u001b[0m | \u001b[0m0.8567   \u001b[0m | \u001b[0m0.02043  \u001b[0m | \u001b[0m0.2581   \u001b[0m | \u001b[0m5.718    \u001b[0m | \u001b[0m9.376    \u001b[0m | \u001b[0m470.7    \u001b[0m | \u001b[0m0.6339   \u001b[0m |\n",
      "| \u001b[0m31       \u001b[0m | \u001b[0m0.8249   \u001b[0m | \u001b[0m0.8813   \u001b[0m | \u001b[0m0.1042   \u001b[0m | \u001b[0m0.03411  \u001b[0m | \u001b[0m5.147    \u001b[0m | \u001b[0m2.894    \u001b[0m | \u001b[0m470.0    \u001b[0m | \u001b[0m0.9363   \u001b[0m |\n",
      "| \u001b[0m32       \u001b[0m | \u001b[0m0.8362   \u001b[0m | \u001b[0m0.5617   \u001b[0m | \u001b[0m2.801    \u001b[0m | \u001b[0m0.1522   \u001b[0m | \u001b[0m3.67     \u001b[0m | \u001b[0m0.6647   \u001b[0m | \u001b[0m471.0    \u001b[0m | \u001b[0m0.5473   \u001b[0m |\n",
      "| \u001b[95m33       \u001b[0m | \u001b[95m0.8418   \u001b[0m | \u001b[95m0.8808   \u001b[0m | \u001b[95m2.57     \u001b[0m | \u001b[95m0.1275   \u001b[0m | \u001b[95m3.21     \u001b[0m | \u001b[95m0.2431   \u001b[0m | \u001b[95m466.1    \u001b[0m | \u001b[95m0.7818   \u001b[0m |\n",
      "| \u001b[0m34       \u001b[0m | \u001b[0m0.8406   \u001b[0m | \u001b[0m0.705    \u001b[0m | \u001b[0m2.927    \u001b[0m | \u001b[0m0.4418   \u001b[0m | \u001b[0m5.646    \u001b[0m | \u001b[0m0.1042   \u001b[0m | \u001b[0m467.2    \u001b[0m | \u001b[0m0.6738   \u001b[0m |\n",
      "| \u001b[0m35       \u001b[0m | \u001b[0m0.8036   \u001b[0m | \u001b[0m0.5      \u001b[0m | \u001b[0m5.0      \u001b[0m | \u001b[0m0.5      \u001b[0m | \u001b[0m3.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m468.0    \u001b[0m | \u001b[0m1.0      \u001b[0m |\n",
      "| \u001b[0m36       \u001b[0m | \u001b[0m0.835    \u001b[0m | \u001b[0m0.6592   \u001b[0m | \u001b[0m1.036    \u001b[0m | \u001b[0m0.3462   \u001b[0m | \u001b[0m3.972    \u001b[0m | \u001b[0m1.932    \u001b[0m | \u001b[0m465.0    \u001b[0m | \u001b[0m0.9393   \u001b[0m |\n",
      "| \u001b[0m37       \u001b[0m | \u001b[0m0.8384   \u001b[0m | \u001b[0m0.543    \u001b[0m | \u001b[0m2.311    \u001b[0m | \u001b[0m0.3386   \u001b[0m | \u001b[0m6.508    \u001b[0m | \u001b[0m0.3939   \u001b[0m | \u001b[0m470.4    \u001b[0m | \u001b[0m0.5      \u001b[0m |\n",
      "| \u001b[0m38       \u001b[0m | \u001b[0m0.826    \u001b[0m | \u001b[0m0.9344   \u001b[0m | \u001b[0m0.785    \u001b[0m | \u001b[0m0.3433   \u001b[0m | \u001b[0m3.042    \u001b[0m | \u001b[0m0.05596  \u001b[0m | \u001b[0m466.8    \u001b[0m | \u001b[0m0.6167   \u001b[0m |\n",
      "| \u001b[0m39       \u001b[0m | \u001b[0m0.8317   \u001b[0m | \u001b[0m0.566    \u001b[0m | \u001b[0m1.839    \u001b[0m | \u001b[0m0.2178   \u001b[0m | \u001b[0m5.433    \u001b[0m | \u001b[0m1.405    \u001b[0m | \u001b[0m465.8    \u001b[0m | \u001b[0m0.5774   \u001b[0m |\n",
      "| \u001b[0m40       \u001b[0m | \u001b[0m0.8328   \u001b[0m | \u001b[0m0.7417   \u001b[0m | \u001b[0m3.452    \u001b[0m | \u001b[0m0.4267   \u001b[0m | \u001b[0m4.627    \u001b[0m | \u001b[0m0.5499   \u001b[0m | \u001b[0m464.7    \u001b[0m | \u001b[0m0.755    \u001b[0m |\n",
      "| \u001b[0m41       \u001b[0m | \u001b[0m0.8395   \u001b[0m | \u001b[0m0.8953   \u001b[0m | \u001b[0m4.109    \u001b[0m | \u001b[0m0.4447   \u001b[0m | \u001b[0m7.423    \u001b[0m | \u001b[0m0.986    \u001b[0m | \u001b[0m468.6    \u001b[0m | \u001b[0m0.5673   \u001b[0m |\n",
      "| \u001b[0m42       \u001b[0m | \u001b[0m0.8272   \u001b[0m | \u001b[0m0.8341   \u001b[0m | \u001b[0m3.498    \u001b[0m | \u001b[0m0.2484   \u001b[0m | \u001b[0m7.489    \u001b[0m | \u001b[0m2.149    \u001b[0m | \u001b[0m470.5    \u001b[0m | \u001b[0m0.5111   \u001b[0m |\n",
      "| \u001b[0m43       \u001b[0m | \u001b[0m0.8171   \u001b[0m | \u001b[0m0.5445   \u001b[0m | \u001b[0m4.853    \u001b[0m | \u001b[0m0.2505   \u001b[0m | \u001b[0m6.933    \u001b[0m | \u001b[0m1.64     \u001b[0m | \u001b[0m467.1    \u001b[0m | \u001b[0m0.7025   \u001b[0m |\n",
      "| \u001b[0m44       \u001b[0m | \u001b[0m0.8305   \u001b[0m | \u001b[0m0.653    \u001b[0m | \u001b[0m2.286    \u001b[0m | \u001b[0m0.1733   \u001b[0m | \u001b[0m4.777    \u001b[0m | \u001b[0m1.886    \u001b[0m | \u001b[0m468.4    \u001b[0m | \u001b[0m0.9862   \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m45       \u001b[0m | \u001b[0m0.8373   \u001b[0m | \u001b[0m0.5408   \u001b[0m | \u001b[0m0.5721   \u001b[0m | \u001b[0m0.07684  \u001b[0m | \u001b[0m5.78     \u001b[0m | \u001b[0m0.9057   \u001b[0m | \u001b[0m472.6    \u001b[0m | \u001b[0m0.635    \u001b[0m |\n",
      "| \u001b[0m46       \u001b[0m | \u001b[0m0.8294   \u001b[0m | \u001b[0m0.554    \u001b[0m | \u001b[0m2.757    \u001b[0m | \u001b[0m0.1289   \u001b[0m | \u001b[0m6.203    \u001b[0m | \u001b[0m0.4282   \u001b[0m | \u001b[0m472.0    \u001b[0m | \u001b[0m0.8836   \u001b[0m |\n",
      "| \u001b[0m47       \u001b[0m | \u001b[0m0.8361   \u001b[0m | \u001b[0m0.5619   \u001b[0m | \u001b[0m2.377    \u001b[0m | \u001b[0m0.05325  \u001b[0m | \u001b[0m7.604    \u001b[0m | \u001b[0m0.4086   \u001b[0m | \u001b[0m468.4    \u001b[0m | \u001b[0m0.5463   \u001b[0m |\n",
      "| \u001b[0m48       \u001b[0m | \u001b[0m0.816    \u001b[0m | \u001b[0m0.6179   \u001b[0m | \u001b[0m0.7043   \u001b[0m | \u001b[0m0.4233   \u001b[0m | \u001b[0m9.265    \u001b[0m | \u001b[0m4.387    \u001b[0m | \u001b[0m274.9    \u001b[0m | \u001b[0m0.5625   \u001b[0m |\n",
      "| \u001b[0m49       \u001b[0m | \u001b[0m0.8283   \u001b[0m | \u001b[0m0.8589   \u001b[0m | \u001b[0m0.8296   \u001b[0m | \u001b[0m0.1746   \u001b[0m | \u001b[0m9.144    \u001b[0m | \u001b[0m0.1657   \u001b[0m | \u001b[0m471.4    \u001b[0m | \u001b[0m0.8321   \u001b[0m |\n",
      "| \u001b[0m50       \u001b[0m | \u001b[0m0.8294   \u001b[0m | \u001b[0m0.9791   \u001b[0m | \u001b[0m0.08006  \u001b[0m | \u001b[0m0.3749   \u001b[0m | \u001b[0m7.32     \u001b[0m | \u001b[0m0.2927   \u001b[0m | \u001b[0m470.2    \u001b[0m | \u001b[0m0.9772   \u001b[0m |\n",
      "| \u001b[0m51       \u001b[0m | \u001b[0m0.8272   \u001b[0m | \u001b[0m0.8773   \u001b[0m | \u001b[0m3.333    \u001b[0m | \u001b[0m0.4413   \u001b[0m | \u001b[0m3.576    \u001b[0m | \u001b[0m3.123    \u001b[0m | \u001b[0m470.8    \u001b[0m | \u001b[0m0.6641   \u001b[0m |\n",
      "| \u001b[0m52       \u001b[0m | \u001b[0m0.8294   \u001b[0m | \u001b[0m0.6108   \u001b[0m | \u001b[0m2.705    \u001b[0m | \u001b[0m0.3609   \u001b[0m | \u001b[0m5.419    \u001b[0m | \u001b[0m0.1434   \u001b[0m | \u001b[0m470.2    \u001b[0m | \u001b[0m0.9908   \u001b[0m |\n",
      "| \u001b[0m53       \u001b[0m | \u001b[0m0.835    \u001b[0m | \u001b[0m0.6135   \u001b[0m | \u001b[0m3.563    \u001b[0m | \u001b[0m0.3948   \u001b[0m | \u001b[0m8.971    \u001b[0m | \u001b[0m1.306    \u001b[0m | \u001b[0m469.0    \u001b[0m | \u001b[0m0.688    \u001b[0m |\n",
      "| \u001b[0m54       \u001b[0m | \u001b[0m0.8205   \u001b[0m | \u001b[0m0.9629   \u001b[0m | \u001b[0m0.4158   \u001b[0m | \u001b[0m0.442    \u001b[0m | \u001b[0m3.079    \u001b[0m | \u001b[0m0.03492  \u001b[0m | \u001b[0m472.7    \u001b[0m | \u001b[0m0.714    \u001b[0m |\n",
      "| \u001b[0m55       \u001b[0m | \u001b[0m0.8261   \u001b[0m | \u001b[0m0.5391   \u001b[0m | \u001b[0m2.789    \u001b[0m | \u001b[0m0.3939   \u001b[0m | \u001b[0m3.144    \u001b[0m | \u001b[0m1.936    \u001b[0m | \u001b[0m465.6    \u001b[0m | \u001b[0m0.9111   \u001b[0m |\n",
      "| \u001b[0m56       \u001b[0m | \u001b[0m0.8294   \u001b[0m | \u001b[0m0.6022   \u001b[0m | \u001b[0m1.544    \u001b[0m | \u001b[0m0.3733   \u001b[0m | \u001b[0m6.137    \u001b[0m | \u001b[0m0.7245   \u001b[0m | \u001b[0m469.2    \u001b[0m | \u001b[0m0.9071   \u001b[0m |\n",
      "| \u001b[0m57       \u001b[0m | \u001b[0m0.8205   \u001b[0m | \u001b[0m0.7773   \u001b[0m | \u001b[0m1.332    \u001b[0m | \u001b[0m0.4959   \u001b[0m | \u001b[0m6.515    \u001b[0m | \u001b[0m2.348    \u001b[0m | \u001b[0m470.8    \u001b[0m | \u001b[0m0.5853   \u001b[0m |\n",
      "| \u001b[0m58       \u001b[0m | \u001b[0m0.8294   \u001b[0m | \u001b[0m0.9273   \u001b[0m | \u001b[0m1.775    \u001b[0m | \u001b[0m0.316    \u001b[0m | \u001b[0m7.892    \u001b[0m | \u001b[0m1.513    \u001b[0m | \u001b[0m473.7    \u001b[0m | \u001b[0m0.6554   \u001b[0m |\n",
      "| \u001b[0m59       \u001b[0m | \u001b[0m0.8294   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m3.454    \u001b[0m | \u001b[0m0.5      \u001b[0m | \u001b[0m7.617    \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m469.6    \u001b[0m | \u001b[0m0.5      \u001b[0m |\n",
      "| \u001b[0m60       \u001b[0m | \u001b[0m0.8373   \u001b[0m | \u001b[0m0.6164   \u001b[0m | \u001b[0m3.18     \u001b[0m | \u001b[0m0.1597   \u001b[0m | \u001b[0m7.29     \u001b[0m | \u001b[0m0.1204   \u001b[0m | \u001b[0m467.4    \u001b[0m | \u001b[0m0.6917   \u001b[0m |\n",
      "| \u001b[0m61       \u001b[0m | \u001b[0m0.835    \u001b[0m | \u001b[0m0.5007   \u001b[0m | \u001b[0m1.157    \u001b[0m | \u001b[0m0.1644   \u001b[0m | \u001b[0m3.749    \u001b[0m | \u001b[0m4.255    \u001b[0m | \u001b[0m469.5    \u001b[0m | \u001b[0m0.7203   \u001b[0m |\n",
      "| \u001b[0m62       \u001b[0m | \u001b[0m0.8238   \u001b[0m | \u001b[0m0.9838   \u001b[0m | \u001b[0m3.249    \u001b[0m | \u001b[0m0.4044   \u001b[0m | \u001b[0m5.737    \u001b[0m | \u001b[0m4.532    \u001b[0m | \u001b[0m469.3    \u001b[0m | \u001b[0m0.5933   \u001b[0m |\n",
      "| \u001b[0m63       \u001b[0m | \u001b[0m0.8339   \u001b[0m | \u001b[0m0.9718   \u001b[0m | \u001b[0m1.617    \u001b[0m | \u001b[0m0.1432   \u001b[0m | \u001b[0m5.31     \u001b[0m | \u001b[0m0.5508   \u001b[0m | \u001b[0m467.3    \u001b[0m | \u001b[0m0.7957   \u001b[0m |\n",
      "| \u001b[0m64       \u001b[0m | \u001b[0m0.8283   \u001b[0m | \u001b[0m0.8903   \u001b[0m | \u001b[0m0.5897   \u001b[0m | \u001b[0m0.399    \u001b[0m | \u001b[0m6.225    \u001b[0m | \u001b[0m0.2063   \u001b[0m | \u001b[0m471.4    \u001b[0m | \u001b[0m0.6573   \u001b[0m |\n",
      "| \u001b[0m65       \u001b[0m | \u001b[0m0.8384   \u001b[0m | \u001b[0m0.9341   \u001b[0m | \u001b[0m2.192    \u001b[0m | \u001b[0m0.09484  \u001b[0m | \u001b[0m4.831    \u001b[0m | \u001b[0m0.2072   \u001b[0m | \u001b[0m466.2    \u001b[0m | \u001b[0m0.5312   \u001b[0m |\n",
      "| \u001b[0m66       \u001b[0m | \u001b[0m0.8317   \u001b[0m | \u001b[0m0.7878   \u001b[0m | \u001b[0m0.9633   \u001b[0m | \u001b[0m0.1459   \u001b[0m | \u001b[0m3.222    \u001b[0m | \u001b[0m2.716    \u001b[0m | \u001b[0m469.6    \u001b[0m | \u001b[0m0.6237   \u001b[0m |\n",
      "| \u001b[0m67       \u001b[0m | \u001b[0m0.8137   \u001b[0m | \u001b[0m0.7522   \u001b[0m | \u001b[0m0.8017   \u001b[0m | \u001b[0m0.2877   \u001b[0m | \u001b[0m7.321    \u001b[0m | \u001b[0m6.063    \u001b[0m | \u001b[0m272.2    \u001b[0m | \u001b[0m0.5629   \u001b[0m |\n",
      "| \u001b[0m68       \u001b[0m | \u001b[0m0.8339   \u001b[0m | \u001b[0m0.9721   \u001b[0m | \u001b[0m1.374    \u001b[0m | \u001b[0m0.01701  \u001b[0m | \u001b[0m3.835    \u001b[0m | \u001b[0m0.09751  \u001b[0m | \u001b[0m465.1    \u001b[0m | \u001b[0m0.8301   \u001b[0m |\n",
      "| \u001b[0m69       \u001b[0m | \u001b[0m0.8373   \u001b[0m | \u001b[0m0.9318   \u001b[0m | \u001b[0m3.404    \u001b[0m | \u001b[0m0.1574   \u001b[0m | \u001b[0m3.482    \u001b[0m | \u001b[0m0.1197   \u001b[0m | \u001b[0m465.3    \u001b[0m | \u001b[0m0.6861   \u001b[0m |\n",
      "| \u001b[0m70       \u001b[0m | \u001b[0m0.8205   \u001b[0m | \u001b[0m0.5592   \u001b[0m | \u001b[0m0.1803   \u001b[0m | \u001b[0m0.2212   \u001b[0m | \u001b[0m4.275    \u001b[0m | \u001b[0m4.631    \u001b[0m | \u001b[0m464.3    \u001b[0m | \u001b[0m0.5487   \u001b[0m |\n",
      "| \u001b[0m71       \u001b[0m | \u001b[0m0.8294   \u001b[0m | \u001b[0m0.8015   \u001b[0m | \u001b[0m0.6151   \u001b[0m | \u001b[0m0.4907   \u001b[0m | \u001b[0m9.898    \u001b[0m | \u001b[0m2.79     \u001b[0m | \u001b[0m472.5    \u001b[0m | \u001b[0m0.9912   \u001b[0m |\n",
      "| \u001b[0m72       \u001b[0m | \u001b[0m0.8339   \u001b[0m | \u001b[0m0.7348   \u001b[0m | \u001b[0m0.01184  \u001b[0m | \u001b[0m0.01943  \u001b[0m | \u001b[0m7.052    \u001b[0m | \u001b[0m1.281    \u001b[0m | \u001b[0m473.5    \u001b[0m | \u001b[0m0.6548   \u001b[0m |\n",
      "| \u001b[0m73       \u001b[0m | \u001b[0m0.8238   \u001b[0m | \u001b[0m0.6092   \u001b[0m | \u001b[0m2.012    \u001b[0m | \u001b[0m0.07272  \u001b[0m | \u001b[0m9.384    \u001b[0m | \u001b[0m7.117    \u001b[0m | \u001b[0m274.2    \u001b[0m | \u001b[0m0.8928   \u001b[0m |\n",
      "| \u001b[0m74       \u001b[0m | \u001b[0m0.8328   \u001b[0m | \u001b[0m0.9921   \u001b[0m | \u001b[0m3.255    \u001b[0m | \u001b[0m0.2076   \u001b[0m | \u001b[0m5.78     \u001b[0m | \u001b[0m0.568    \u001b[0m | \u001b[0m468.1    \u001b[0m | \u001b[0m0.7588   \u001b[0m |\n",
      "| \u001b[0m75       \u001b[0m | \u001b[0m0.8272   \u001b[0m | \u001b[0m0.5726   \u001b[0m | \u001b[0m0.3868   \u001b[0m | \u001b[0m0.2153   \u001b[0m | \u001b[0m3.253    \u001b[0m | \u001b[0m6.062    \u001b[0m | \u001b[0m470.0    \u001b[0m | \u001b[0m0.9431   \u001b[0m |\n",
      "| \u001b[0m76       \u001b[0m | \u001b[0m0.8317   \u001b[0m | \u001b[0m0.9581   \u001b[0m | \u001b[0m3.636    \u001b[0m | \u001b[0m0.298    \u001b[0m | \u001b[0m8.814    \u001b[0m | \u001b[0m1.419    \u001b[0m | \u001b[0m467.4    \u001b[0m | \u001b[0m0.7077   \u001b[0m |\n",
      "| \u001b[0m77       \u001b[0m | \u001b[0m0.8373   \u001b[0m | \u001b[0m0.613    \u001b[0m | \u001b[0m0.927    \u001b[0m | \u001b[0m0.2593   \u001b[0m | \u001b[0m5.37     \u001b[0m | \u001b[0m0.487    \u001b[0m | \u001b[0m462.6    \u001b[0m | \u001b[0m0.8263   \u001b[0m |\n",
      "| \u001b[0m78       \u001b[0m | \u001b[0m0.8283   \u001b[0m | \u001b[0m0.9721   \u001b[0m | \u001b[0m1.348    \u001b[0m | \u001b[0m0.3239   \u001b[0m | \u001b[0m7.13     \u001b[0m | \u001b[0m1.74     \u001b[0m | \u001b[0m463.8    \u001b[0m | \u001b[0m0.7665   \u001b[0m |\n",
      "| \u001b[0m79       \u001b[0m | \u001b[0m0.8361   \u001b[0m | \u001b[0m0.9026   \u001b[0m | \u001b[0m1.967    \u001b[0m | \u001b[0m0.07841  \u001b[0m | \u001b[0m4.216    \u001b[0m | \u001b[0m0.6068   \u001b[0m | \u001b[0m461.7    \u001b[0m | \u001b[0m0.8782   \u001b[0m |\n",
      "| \u001b[0m80       \u001b[0m | \u001b[0m0.8361   \u001b[0m | \u001b[0m0.746    \u001b[0m | \u001b[0m0.2312   \u001b[0m | \u001b[0m0.03447  \u001b[0m | \u001b[0m3.234    \u001b[0m | \u001b[0m1.172    \u001b[0m | \u001b[0m462.1    \u001b[0m | \u001b[0m0.9262   \u001b[0m |\n",
      "| \u001b[0m81       \u001b[0m | \u001b[0m0.8316   \u001b[0m | \u001b[0m0.6966   \u001b[0m | \u001b[0m1.644    \u001b[0m | \u001b[0m0.4484   \u001b[0m | \u001b[0m3.051    \u001b[0m | \u001b[0m0.3213   \u001b[0m | \u001b[0m462.5    \u001b[0m | \u001b[0m0.6756   \u001b[0m |\n",
      "| \u001b[0m82       \u001b[0m | \u001b[0m0.8373   \u001b[0m | \u001b[0m0.9644   \u001b[0m | \u001b[0m1.122    \u001b[0m | \u001b[0m0.08407  \u001b[0m | \u001b[0m4.69     \u001b[0m | \u001b[0m1.028    \u001b[0m | \u001b[0m460.4    \u001b[0m | \u001b[0m0.8316   \u001b[0m |\n",
      "| \u001b[0m83       \u001b[0m | \u001b[0m0.8384   \u001b[0m | \u001b[0m0.6048   \u001b[0m | \u001b[0m1.09     \u001b[0m | \u001b[0m0.4127   \u001b[0m | \u001b[0m5.188    \u001b[0m | \u001b[0m1.997    \u001b[0m | \u001b[0m462.7    \u001b[0m | \u001b[0m0.7887   \u001b[0m |\n",
      "| \u001b[0m84       \u001b[0m | \u001b[0m0.8362   \u001b[0m | \u001b[0m0.8152   \u001b[0m | \u001b[0m1.253    \u001b[0m | \u001b[0m0.1879   \u001b[0m | \u001b[0m3.182    \u001b[0m | \u001b[0m2.779    \u001b[0m | \u001b[0m461.5    \u001b[0m | \u001b[0m0.8682   \u001b[0m |\n",
      "| \u001b[0m85       \u001b[0m | \u001b[0m0.8384   \u001b[0m | \u001b[0m0.7197   \u001b[0m | \u001b[0m2.273    \u001b[0m | \u001b[0m0.1589   \u001b[0m | \u001b[0m4.602    \u001b[0m | \u001b[0m2.474    \u001b[0m | \u001b[0m460.9    \u001b[0m | \u001b[0m0.6685   \u001b[0m |\n",
      "| \u001b[0m86       \u001b[0m | \u001b[0m0.8305   \u001b[0m | \u001b[0m0.5218   \u001b[0m | \u001b[0m3.275    \u001b[0m | \u001b[0m0.05661  \u001b[0m | \u001b[0m6.034    \u001b[0m | \u001b[0m1.638    \u001b[0m | \u001b[0m461.8    \u001b[0m | \u001b[0m0.541    \u001b[0m |\n",
      "| \u001b[0m87       \u001b[0m | \u001b[0m0.8227   \u001b[0m | \u001b[0m0.8451   \u001b[0m | \u001b[0m1.278    \u001b[0m | \u001b[0m0.337    \u001b[0m | \u001b[0m4.895    \u001b[0m | \u001b[0m3.153    \u001b[0m | \u001b[0m458.9    \u001b[0m | \u001b[0m0.5367   \u001b[0m |\n",
      "| \u001b[0m88       \u001b[0m | \u001b[0m0.826    \u001b[0m | \u001b[0m0.817    \u001b[0m | \u001b[0m2.613    \u001b[0m | \u001b[0m0.4998   \u001b[0m | \u001b[0m3.496    \u001b[0m | \u001b[0m1.287    \u001b[0m | \u001b[0m459.3    \u001b[0m | \u001b[0m0.9758   \u001b[0m |\n",
      "| \u001b[0m89       \u001b[0m | \u001b[0m0.8305   \u001b[0m | \u001b[0m0.9279   \u001b[0m | \u001b[0m0.7044   \u001b[0m | \u001b[0m0.4325   \u001b[0m | \u001b[0m6.038    \u001b[0m | \u001b[0m1.177    \u001b[0m | \u001b[0m462.0    \u001b[0m | \u001b[0m0.746    \u001b[0m |\n",
      "| \u001b[0m90       \u001b[0m | \u001b[0m0.8306   \u001b[0m | \u001b[0m0.6979   \u001b[0m | \u001b[0m2.83     \u001b[0m | \u001b[0m0.4294   \u001b[0m | \u001b[0m3.163    \u001b[0m | \u001b[0m3.126    \u001b[0m | \u001b[0m462.4    \u001b[0m | \u001b[0m0.5658   \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m91       \u001b[0m | \u001b[0m0.8351   \u001b[0m | \u001b[0m0.7445   \u001b[0m | \u001b[0m0.2413   \u001b[0m | \u001b[0m0.2308   \u001b[0m | \u001b[0m4.896    \u001b[0m | \u001b[0m2.064    \u001b[0m | \u001b[0m460.7    \u001b[0m | \u001b[0m0.7139   \u001b[0m |\n",
      "| \u001b[0m92       \u001b[0m | \u001b[0m0.826    \u001b[0m | \u001b[0m0.5181   \u001b[0m | \u001b[0m1.882    \u001b[0m | \u001b[0m0.4305   \u001b[0m | \u001b[0m5.876    \u001b[0m | \u001b[0m0.01668  \u001b[0m | \u001b[0m459.8    \u001b[0m | \u001b[0m0.515    \u001b[0m |\n",
      "| \u001b[0m93       \u001b[0m | \u001b[0m0.8384   \u001b[0m | \u001b[0m0.8795   \u001b[0m | \u001b[0m2.485    \u001b[0m | \u001b[0m0.2753   \u001b[0m | \u001b[0m8.491    \u001b[0m | \u001b[0m0.5225   \u001b[0m | \u001b[0m268.8    \u001b[0m | \u001b[0m0.6907   \u001b[0m |\n",
      "| \u001b[0m94       \u001b[0m | \u001b[0m0.826    \u001b[0m | \u001b[0m0.9045   \u001b[0m | \u001b[0m2.546    \u001b[0m | \u001b[0m0.3375   \u001b[0m | \u001b[0m8.672    \u001b[0m | \u001b[0m0.8401   \u001b[0m | \u001b[0m267.1    \u001b[0m | \u001b[0m0.5503   \u001b[0m |\n",
      "| \u001b[0m95       \u001b[0m | \u001b[0m0.8272   \u001b[0m | \u001b[0m0.9044   \u001b[0m | \u001b[0m2.486    \u001b[0m | \u001b[0m0.2896   \u001b[0m | \u001b[0m8.173    \u001b[0m | \u001b[0m0.02304  \u001b[0m | \u001b[0m270.7    \u001b[0m | \u001b[0m0.8982   \u001b[0m |\n",
      "| \u001b[0m96       \u001b[0m | \u001b[0m0.8306   \u001b[0m | \u001b[0m0.8364   \u001b[0m | \u001b[0m0.3332   \u001b[0m | \u001b[0m0.2159   \u001b[0m | \u001b[0m4.345    \u001b[0m | \u001b[0m1.631    \u001b[0m | \u001b[0m463.2    \u001b[0m | \u001b[0m0.7638   \u001b[0m |\n",
      "| \u001b[0m97       \u001b[0m | \u001b[0m0.835    \u001b[0m | \u001b[0m0.7624   \u001b[0m | \u001b[0m1.422    \u001b[0m | \u001b[0m0.398    \u001b[0m | \u001b[0m9.516    \u001b[0m | \u001b[0m2.044    \u001b[0m | \u001b[0m269.8    \u001b[0m | \u001b[0m0.8617   \u001b[0m |\n",
      "| \u001b[0m98       \u001b[0m | \u001b[0m0.8294   \u001b[0m | \u001b[0m0.7754   \u001b[0m | \u001b[0m4.542    \u001b[0m | \u001b[0m0.3541   \u001b[0m | \u001b[0m9.453    \u001b[0m | \u001b[0m0.4507   \u001b[0m | \u001b[0m268.5    \u001b[0m | \u001b[0m0.5821   \u001b[0m |\n",
      "| \u001b[0m99       \u001b[0m | \u001b[0m0.8193   \u001b[0m | \u001b[0m0.7531   \u001b[0m | \u001b[0m3.733    \u001b[0m | \u001b[0m0.07184  \u001b[0m | \u001b[0m8.31     \u001b[0m | \u001b[0m2.335    \u001b[0m | \u001b[0m269.0    \u001b[0m | \u001b[0m0.6003   \u001b[0m |\n",
      "| \u001b[0m100      \u001b[0m | \u001b[0m0.8227   \u001b[0m | \u001b[0m0.5837   \u001b[0m | \u001b[0m2.089    \u001b[0m | \u001b[0m0.4955   \u001b[0m | \u001b[0m4.893    \u001b[0m | \u001b[0m1.794    \u001b[0m | \u001b[0m462.1    \u001b[0m | \u001b[0m0.958    \u001b[0m |\n",
      "| \u001b[0m101      \u001b[0m | \u001b[0m0.8395   \u001b[0m | \u001b[0m0.5662   \u001b[0m | \u001b[0m2.101    \u001b[0m | \u001b[0m0.1739   \u001b[0m | \u001b[0m9.521    \u001b[0m | \u001b[0m0.6474   \u001b[0m | \u001b[0m269.3    \u001b[0m | \u001b[0m0.7744   \u001b[0m |\n",
      "| \u001b[0m102      \u001b[0m | \u001b[0m0.8227   \u001b[0m | \u001b[0m0.592    \u001b[0m | \u001b[0m1.938    \u001b[0m | \u001b[0m0.01484  \u001b[0m | \u001b[0m3.505    \u001b[0m | \u001b[0m4.875    \u001b[0m | \u001b[0m468.1    \u001b[0m | \u001b[0m0.5756   \u001b[0m |\n",
      "| \u001b[0m103      \u001b[0m | \u001b[0m0.8294   \u001b[0m | \u001b[0m0.9078   \u001b[0m | \u001b[0m2.982    \u001b[0m | \u001b[0m0.2979   \u001b[0m | \u001b[0m4.712    \u001b[0m | \u001b[0m1.054    \u001b[0m | \u001b[0m466.4    \u001b[0m | \u001b[0m0.9361   \u001b[0m |\n",
      "| \u001b[0m104      \u001b[0m | \u001b[0m0.8272   \u001b[0m | \u001b[0m0.5693   \u001b[0m | \u001b[0m2.811    \u001b[0m | \u001b[0m0.4304   \u001b[0m | \u001b[0m6.083    \u001b[0m | \u001b[0m0.0853   \u001b[0m | \u001b[0m465.3    \u001b[0m | \u001b[0m0.765    \u001b[0m |\n",
      "| \u001b[0m105      \u001b[0m | \u001b[0m0.835    \u001b[0m | \u001b[0m0.5      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.01     \u001b[0m | \u001b[0m8.229    \u001b[0m | \u001b[0m2.023    \u001b[0m | \u001b[0m472.5    \u001b[0m | \u001b[0m1.0      \u001b[0m |\n",
      "| \u001b[0m106      \u001b[0m | \u001b[0m0.8339   \u001b[0m | \u001b[0m0.7262   \u001b[0m | \u001b[0m2.266    \u001b[0m | \u001b[0m0.4813   \u001b[0m | \u001b[0m4.524    \u001b[0m | \u001b[0m4.146    \u001b[0m | \u001b[0m461.3    \u001b[0m | \u001b[0m0.629    \u001b[0m |\n",
      "| \u001b[0m107      \u001b[0m | \u001b[0m0.835    \u001b[0m | \u001b[0m0.5999   \u001b[0m | \u001b[0m1.382    \u001b[0m | \u001b[0m0.4186   \u001b[0m | \u001b[0m4.066    \u001b[0m | \u001b[0m1.279    \u001b[0m | \u001b[0m471.2    \u001b[0m | \u001b[0m0.7872   \u001b[0m |\n",
      "| \u001b[0m108      \u001b[0m | \u001b[0m0.8249   \u001b[0m | \u001b[0m0.599    \u001b[0m | \u001b[0m0.1425   \u001b[0m | \u001b[0m0.1252   \u001b[0m | \u001b[0m9.805    \u001b[0m | \u001b[0m0.3162   \u001b[0m | \u001b[0m268.2    \u001b[0m | \u001b[0m0.5865   \u001b[0m |\n",
      "| \u001b[0m109      \u001b[0m | \u001b[0m0.8328   \u001b[0m | \u001b[0m0.5      \u001b[0m | \u001b[0m0.8466   \u001b[0m | \u001b[0m0.5      \u001b[0m | \u001b[0m6.524    \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m473.5    \u001b[0m | \u001b[0m1.0      \u001b[0m |\n",
      "| \u001b[0m110      \u001b[0m | \u001b[0m0.8227   \u001b[0m | \u001b[0m0.9005   \u001b[0m | \u001b[0m0.1904   \u001b[0m | \u001b[0m0.351    \u001b[0m | \u001b[0m4.68     \u001b[0m | \u001b[0m3.422    \u001b[0m | \u001b[0m461.8    \u001b[0m | \u001b[0m0.9787   \u001b[0m |\n",
      "=============================================================================================================\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# 파라미터 범위 설정\n",
    "pbounds = {\n",
    "    'learning_rate': (0.01, 0.5),\n",
    "    'n_estimators': (100, 1000),\n",
    "    'max_depth': (3, 10),\n",
    "    'min_child_weight': (0, 10),\n",
    "    'subsample': (0.5, 1.0),\n",
    "    'colsample_bytree': (0.5, 1.0),\n",
    "    'gamma': (0, 5)\n",
    "}\n",
    "\n",
    "def xgboost_hyper_param(learning_rate, n_estimators, max_depth, min_child_weight, subsample, colsample_bytree, gamma):\n",
    "    max_depth = int(max_depth)\n",
    "    n_estimators = int(n_estimators)\n",
    "    clf = XGBClassifier(\n",
    "        max_depth=max_depth, \n",
    "        min_child_weight=min_child_weight,\n",
    "        learning_rate=learning_rate, \n",
    "        n_estimators=n_estimators, \n",
    "        subsample=subsample, \n",
    "        colsample_bytree=colsample_bytree, \n",
    "        gamma=gamma,\n",
    "        random_state=1,\n",
    "        eval_metric='logloss'\n",
    "    )\n",
    "    # train_importance와 train_answer는 적절한 학습 데이터와 레이블로 대체되어야 합니다.\n",
    "    return np.mean(cross_val_score(clf, train_importance, train_answer, cv=5, scoring='accuracy'))\n",
    "\n",
    "optimizer = BayesianOptimization(f=xgboost_hyper_param, pbounds=pbounds, random_state=1)\n",
    "\n",
    "# 202402 업데이트: Bayesian Optimization 라이브러리에서는 maximize 메소드의 사용법이 변경되어\n",
    "# maximize() 메서드에서 acq 와 xi 를 직접 설정시 에러가 납니다. 따라서 해당 코드를 삭제하였습니다.\n",
    "# 기존 코드: optimizer.maximize(init_points=10, n_iter=100, acq='ei', xi=0.01)\n",
    "# maximize 메소드 호출\n",
    "optimizer.maximize(init_points=10, n_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': 0.8417676228736426,\n",
       " 'params': {'colsample_bytree': 0.8807723303986221,\n",
       "  'gamma': 2.570020856775378,\n",
       "  'learning_rate': 0.12746523282980712,\n",
       "  'max_depth': 3.210428380628923,\n",
       "  'min_child_weight': 0.24311569232482566,\n",
       "  'n_estimators': 466.11090542650936,\n",
       "  'subsample': 0.7817975657827123}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block\" style=\"border: 2px solid #E65100;background-color:#FFF3E0;padding:10px\">\n",
    "<font size=\"4em\" style=\"font-weight:bold;color:#BF360C;\">큰그림으로 이해하기</font><br>\n",
    "<font size=\"4em\" style=\"color:#BF360C;\">데이터를 어떻게 짜르느냐에 따라, 예측 성능은 다르게 계산될 수 있지만,</font><br>\n",
    "<font size=\"4em\" style=\"color:#BF360C;\">동일한 테스트 환경에서, 하이퍼파라미터 튜닝 전, XGBoost 는 약 82.26% 였지만, 튜닝 후, 84.51% 까지 예측 정확도가 올라감</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian Optimization LightGBM 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... | learni... | max_depth | min_ch... | n_esti... | subsample |\n",
      "-------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m0.8316   \u001b[0m | \u001b[0m0.7085   \u001b[0m | \u001b[0m0.1469   \u001b[0m | \u001b[0m3.0      \u001b[0m | \u001b[0m3.721    \u001b[0m | \u001b[0m158.7    \u001b[0m | \u001b[0m0.5462   \u001b[0m |\n",
      "| \u001b[0m2        \u001b[0m | \u001b[0m0.826    \u001b[0m | \u001b[0m0.5931   \u001b[0m | \u001b[0m0.07566  \u001b[0m | \u001b[0m4.587    \u001b[0m | \u001b[0m5.849    \u001b[0m | \u001b[0m267.7    \u001b[0m | \u001b[0m0.8426   \u001b[0m |\n",
      "| \u001b[0m3        \u001b[0m | \u001b[0m0.8215   \u001b[0m | \u001b[0m0.6022   \u001b[0m | \u001b[0m0.1768   \u001b[0m | \u001b[0m3.11     \u001b[0m | \u001b[0m7.034    \u001b[0m | \u001b[0m266.9    \u001b[0m | \u001b[0m0.7793   \u001b[0m |\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m0.8137   \u001b[0m | \u001b[0m0.5702   \u001b[0m | \u001b[0m0.04764  \u001b[0m | \u001b[0m6.203    \u001b[0m | \u001b[0m9.714    \u001b[0m | \u001b[0m225.4    \u001b[0m | \u001b[0m0.8462   \u001b[0m |\n",
      "| \u001b[0m5        \u001b[0m | \u001b[0m0.8227   \u001b[0m | \u001b[0m0.9382   \u001b[0m | \u001b[0m0.18     \u001b[0m | \u001b[0m3.34     \u001b[0m | \u001b[0m1.351    \u001b[0m | \u001b[0m167.9    \u001b[0m | \u001b[0m0.9391   \u001b[0m |\n",
      "| \u001b[0m6        \u001b[0m | \u001b[0m0.8238   \u001b[0m | \u001b[0m0.7807   \u001b[0m | \u001b[0m0.08132  \u001b[0m | \u001b[0m4.916    \u001b[0m | \u001b[0m6.051    \u001b[0m | \u001b[0m155.1    \u001b[0m | \u001b[0m0.8223   \u001b[0m |\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m0.8294   \u001b[0m | \u001b[0m0.7989   \u001b[0m | \u001b[0m0.0705   \u001b[0m | \u001b[0m5.652    \u001b[0m | \u001b[0m5.036    \u001b[0m | \u001b[0m168.9    \u001b[0m | \u001b[0m0.6515   \u001b[0m |\n",
      "| \u001b[95m8        \u001b[0m | \u001b[95m0.835    \u001b[0m | \u001b[95m0.7963   \u001b[0m | \u001b[95m0.1102   \u001b[0m | \u001b[95m3.265    \u001b[0m | \u001b[95m3.901    \u001b[0m | \u001b[95m159.1    \u001b[0m | \u001b[95m0.5615   \u001b[0m |\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m0.8339   \u001b[0m | \u001b[0m0.7643   \u001b[0m | \u001b[0m0.05824  \u001b[0m | \u001b[0m3.466    \u001b[0m | \u001b[0m3.881    \u001b[0m | \u001b[0m160.3    \u001b[0m | \u001b[0m0.9092   \u001b[0m |\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m0.8339   \u001b[0m | \u001b[0m0.7324   \u001b[0m | \u001b[0m0.06591  \u001b[0m | \u001b[0m5.172    \u001b[0m | \u001b[0m4.61     \u001b[0m | \u001b[0m159.5    \u001b[0m | \u001b[0m0.8711   \u001b[0m |\n",
      "| \u001b[0m11       \u001b[0m | \u001b[0m0.8081   \u001b[0m | \u001b[0m0.9979   \u001b[0m | \u001b[0m0.04926  \u001b[0m | \u001b[0m3.311    \u001b[0m | \u001b[0m6.869    \u001b[0m | \u001b[0m160.6    \u001b[0m | \u001b[0m0.5986   \u001b[0m |\n",
      "| \u001b[0m12       \u001b[0m | \u001b[0m0.8305   \u001b[0m | \u001b[0m0.7451   \u001b[0m | \u001b[0m0.04036  \u001b[0m | \u001b[0m4.935    \u001b[0m | \u001b[0m2.912    \u001b[0m | \u001b[0m159.6    \u001b[0m | \u001b[0m0.9094   \u001b[0m |\n",
      "| \u001b[0m13       \u001b[0m | \u001b[0m0.8081   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.01     \u001b[0m | \u001b[0m4.897    \u001b[0m | \u001b[0m4.24     \u001b[0m | \u001b[0m157.9    \u001b[0m | \u001b[0m0.5      \u001b[0m |\n",
      "| \u001b[0m14       \u001b[0m | \u001b[0m0.8305   \u001b[0m | \u001b[0m0.5      \u001b[0m | \u001b[0m0.2      \u001b[0m | \u001b[0m4.429    \u001b[0m | \u001b[0m4.059    \u001b[0m | \u001b[0m160.1    \u001b[0m | \u001b[0m0.5      \u001b[0m |\n",
      "| \u001b[0m15       \u001b[0m | \u001b[0m0.835    \u001b[0m | \u001b[0m0.5227   \u001b[0m | \u001b[0m0.09107  \u001b[0m | \u001b[0m3.437    \u001b[0m | \u001b[0m2.92     \u001b[0m | \u001b[0m161.0    \u001b[0m | \u001b[0m0.8684   \u001b[0m |\n",
      "| \u001b[0m16       \u001b[0m | \u001b[0m0.8294   \u001b[0m | \u001b[0m0.9985   \u001b[0m | \u001b[0m0.02754  \u001b[0m | \u001b[0m4.049    \u001b[0m | \u001b[0m2.928    \u001b[0m | \u001b[0m162.2    \u001b[0m | \u001b[0m0.5242   \u001b[0m |\n",
      "| \u001b[0m17       \u001b[0m | \u001b[0m0.8171   \u001b[0m | \u001b[0m0.5135   \u001b[0m | \u001b[0m0.02933  \u001b[0m | \u001b[0m3.194    \u001b[0m | \u001b[0m2.151    \u001b[0m | \u001b[0m160.5    \u001b[0m | \u001b[0m0.5288   \u001b[0m |\n",
      "| \u001b[0m18       \u001b[0m | \u001b[0m0.8339   \u001b[0m | \u001b[0m0.7707   \u001b[0m | \u001b[0m0.06814  \u001b[0m | \u001b[0m3.104    \u001b[0m | \u001b[0m3.101    \u001b[0m | \u001b[0m161.6    \u001b[0m | \u001b[0m0.8475   \u001b[0m |\n",
      "| \u001b[95m19       \u001b[0m | \u001b[95m0.8361   \u001b[0m | \u001b[95m0.9638   \u001b[0m | \u001b[95m0.1276   \u001b[0m | \u001b[95m3.331    \u001b[0m | \u001b[95m4.271    \u001b[0m | \u001b[95m161.4    \u001b[0m | \u001b[95m0.7823   \u001b[0m |\n",
      "| \u001b[0m20       \u001b[0m | \u001b[0m0.8328   \u001b[0m | \u001b[0m0.9153   \u001b[0m | \u001b[0m0.1101   \u001b[0m | \u001b[0m3.336    \u001b[0m | \u001b[0m4.273    \u001b[0m | \u001b[0m162.8    \u001b[0m | \u001b[0m0.8322   \u001b[0m |\n",
      "| \u001b[0m21       \u001b[0m | \u001b[0m0.835    \u001b[0m | \u001b[0m0.7125   \u001b[0m | \u001b[0m0.15     \u001b[0m | \u001b[0m4.98     \u001b[0m | \u001b[0m3.908    \u001b[0m | \u001b[0m161.5    \u001b[0m | \u001b[0m0.944    \u001b[0m |\n",
      "| \u001b[0m22       \u001b[0m | \u001b[0m0.8316   \u001b[0m | \u001b[0m0.8089   \u001b[0m | \u001b[0m0.03306  \u001b[0m | \u001b[0m6.36     \u001b[0m | \u001b[0m3.845    \u001b[0m | \u001b[0m160.7    \u001b[0m | \u001b[0m0.8583   \u001b[0m |\n",
      "| \u001b[0m23       \u001b[0m | \u001b[0m0.8193   \u001b[0m | \u001b[0m0.7562   \u001b[0m | \u001b[0m0.08195  \u001b[0m | \u001b[0m5.077    \u001b[0m | \u001b[0m5.09     \u001b[0m | \u001b[0m162.3    \u001b[0m | \u001b[0m0.5158   \u001b[0m |\n",
      "| \u001b[0m24       \u001b[0m | \u001b[0m0.8227   \u001b[0m | \u001b[0m0.8828   \u001b[0m | \u001b[0m0.1959   \u001b[0m | \u001b[0m5.104    \u001b[0m | \u001b[0m3.087    \u001b[0m | \u001b[0m161.1    \u001b[0m | \u001b[0m0.7268   \u001b[0m |\n",
      "| \u001b[0m25       \u001b[0m | \u001b[0m0.8305   \u001b[0m | \u001b[0m0.5857   \u001b[0m | \u001b[0m0.05134  \u001b[0m | \u001b[0m5.823    \u001b[0m | \u001b[0m4.549    \u001b[0m | \u001b[0m160.3    \u001b[0m | \u001b[0m0.9997   \u001b[0m |\n",
      "=================================================================================================\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# 202402 업데이트: Bayesian Optimization + LightGBM 사용시, 과도한 메모리 사용으로 주피터 노트북이 다운될 수 있으므로\n",
    "# 주요 파라미터 값을 조정하였습니다. 개인PC 성능에 따라, 그래도 다운된다면, 각 주석을 참고하여, 최대값등을 감소시키면 좋을 것 같습니다.\n",
    "# 파라미터 범위 조정\n",
    "pbounds = {  \n",
    "    'learning_rate': (0.01, 0.2),  # 최대값 감소\n",
    "    'n_estimators': (100, 500),  # 최대값 감소\n",
    "    'max_depth': (3, 7),  # 최대값 감소\n",
    "    'min_child_weight': (1, 10),    \n",
    "    'subsample': (0.5, 1.0),\n",
    "    'colsample_bytree': (0.5, 1.0)\n",
    "}\n",
    "\n",
    "def xgboost_hyper_param(learning_rate, n_estimators, max_depth, min_child_weight, subsample, colsample_bytree):\n",
    "    max_depth = int(max_depth)\n",
    "    n_estimators = int(n_estimators)\n",
    "    clf = XGBClassifier(\n",
    "        max_depth=max_depth,\n",
    "        min_child_weight=min_child_weight,\n",
    "        learning_rate=learning_rate, \n",
    "        n_estimators=n_estimators, \n",
    "        subsample=subsample, \n",
    "        colsample_bytree=colsample_bytree,\n",
    "        random_state=1,\n",
    "        eval_metric='logloss'\n",
    "    )\n",
    "    # cv=3으로 감소, n_jobs=1로 설정하여 병렬 처리 제한\n",
    "    return np.mean(cross_val_score(clf, train_importance, train_answer, cv=3, scoring='accuracy', n_jobs=1))\n",
    "\n",
    "optimizer = BayesianOptimization(f=xgboost_hyper_param, pbounds=pbounds, random_state=1, verbose=2)\n",
    "optimizer.maximize(init_points=5, n_iter=20)  # init_points와 n_iter 감소\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': 0.8361391694725028,\n",
       " 'params': {'colsample_bytree': 0.9638238489542061,\n",
       "  'learning_rate': 0.12755933565380378,\n",
       "  'max_depth': 3.331204265018018,\n",
       "  'min_child_weight': 4.271135115408745,\n",
       "  'n_estimators': 161.41137703963966,\n",
       "  'subsample': 0.7823013849131988}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block\" style=\"border: 2px solid #E65100;background-color:#FFF3E0;padding:10px\">\n",
    "<font size=\"4em\" style=\"font-weight:bold;color:#BF360C;\">큰그림으로 이해하기</font><br>\n",
    "<font size=\"4em\" style=\"color:#BF360C;\">LightGBM 은 수행시간은 XGBoost 보다 단축되고, </font><br>\n",
    "<font size=\"4em\" style=\"color:#BF360C;\">예측 정확도는 거의 유사하거나, 살짝 낮은 정도임을 확인할 수 있으므로, 많은 테스트를 위해서는 LightGBM을 사용하는 것도 좋음</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Grid Search XGBoost 적용\n",
    "\n",
    "### Grid Search XGBoost 적용 1단계\n",
    "- 주요 파라미터를 모두 넣을 경우, 수행시간이 매우 길어지므로, 3단계로 나누어서 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 120 candidates, totalling 600 fits\n",
      "0.8383842822170611\n",
      "{'learning_rate': 0.2, 'n_estimators': 75}\n"
     ]
    }
   ],
   "source": [
    "learning_rate = [0.001, 0.005, 0.01, 0.05, 0.06, 0.1, 0.12, 0.15, 0.17, 0.2]\n",
    "n_estimators = [10, 50, 60, 75, 85, 100, 125, 150, 200, 250, 500, 1000]\n",
    "\n",
    "hyperparams = {\n",
    "    'learning_rate': learning_rate, \n",
    "    'n_estimators': n_estimators\n",
    "}\n",
    "\n",
    "gd=GridSearchCV(\n",
    "    estimator = XGBClassifier(random_state=1, eval_metric='logloss'), \n",
    "    param_grid = hyperparams, \n",
    "    verbose=True, \n",
    "    cv=5, \n",
    "    scoring = \"accuracy\", \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "gd.fit(train_importance, train_answer)\n",
    "print(gd.best_score_)\n",
    "print(gd.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search XGBoost 적용 2단계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 56 candidates, totalling 280 fits\n",
      "0.8383842822170612\n",
      "{'max_depth': 7, 'min_child_weight': 2}\n"
     ]
    }
   ],
   "source": [
    "max_depth = [3, 4, 5, 6, 7, 8, 9, 10]\n",
    "min_child_weight = [1, 2, 3, 4, 5, 6, 7]\n",
    "\n",
    "hyperparams = {\n",
    "    'max_depth': max_depth, \n",
    "    'min_child_weight': min_child_weight\n",
    "}\n",
    "\n",
    "gd=GridSearchCV(\n",
    "    estimator = XGBClassifier(learning_rate=0.17, n_estimators=10, random_state=1, eval_metric='logloss'), \n",
    "    param_grid = hyperparams, \n",
    "    verbose=True, \n",
    "    cv=5, \n",
    "    scoring = \"accuracy\", \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "gd.fit(train_importance, train_answer)\n",
    "print(gd.best_score_)\n",
    "print(gd.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search XGBoost 적용 3단계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2025 candidates, totalling 10125 fits\n",
      "0.8439959826752872\n",
      "{'colsample_bytree': 0.9, 'gamma': 0.0, 'reg_alpha': 1e-05, 'subsample': 0.9}\n"
     ]
    }
   ],
   "source": [
    "gamma =  [i*0.1 for i in range(0,5)]\n",
    "subsample = [0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1]\n",
    "colsample_bytree = [0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1]\n",
    "reg_alpha = [1e-5, 1e-2, 0.1, 1, 100]\n",
    "\n",
    "hyperparams = {\n",
    "    'gamma': gamma,\n",
    "    'subsample':subsample,\n",
    "    'colsample_bytree':colsample_bytree,\n",
    "    'reg_alpha': reg_alpha\n",
    "}\n",
    "\n",
    "gd=GridSearchCV(\n",
    "    estimator = XGBClassifier(\n",
    "        learning_rate=0.17, \n",
    "        n_estimators=10, \n",
    "        max_depth=6, \n",
    "        min_child_weight=1,\n",
    "        random_state=1,\n",
    "        eval_metric='logloss'\n",
    "    ), \n",
    "    param_grid = hyperparams, \n",
    "    verbose=True, \n",
    "    cv=5, \n",
    "    scoring = \"accuracy\", \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "gd.fit(train_importance, train_answer)\n",
    "print(gd.best_score_)\n",
    "print(gd.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block\" style=\"border: 2px solid #E65100;background-color:#FFF3E0;padding:10px\">\n",
    "<font size=\"4em\" style=\"font-weight:bold;color:#BF360C;\">큰그림으로 이해하기</font><br>\n",
    "<font size=\"4em\" style=\"color:#BF360C;\">XGBoost 를 Grid Search 에 적용할 때, </font><br>\n",
    "<font size=\"4em\" style=\"color:#BF360C;\">사전에 여러 테스트를 통해, 파라미터값에 대한 대략적인 감을 가진다면, 보다 좋은 성능 값을 찾아낼 수도 있음</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN (202402 업데이트)\n",
    "- KNN 은 참고차 테스트하는 것이며, 성능이 좋지 않으므로 실제로는 많이 사용되지 않습니다.\n",
    "- 다음 코드는 정상 코드이지만, scikit-learn 1.3.0 의 버그로 실행되지 않습니다.\n",
    "- 해당 코드를 실행하기 위해서는 억지로 1.3.0 이전 버전을 사용하는 방안이 있지만, 추천하지 않습니다.\n",
    "  - 다른 라이브러리와의 또다른 충돌이 예상되며, 이전 버전 사용시 보안 문제로 또다른 문제를 제기하기 때문입니다. \n",
    "\n",
    "```python\n",
    "n_neighbors = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
    "hyperparams = { \n",
    "    'n_neighbors': n_neighbors\n",
    "}\n",
    "\n",
    "gd=GridSearchCV(\n",
    "    estimator = KNeighborsClassifier(), \n",
    "    param_grid = hyperparams, \n",
    "    verbose=True, \n",
    "    cv=5, \n",
    "    scoring = \"accuracy\", \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "gd.fit(train_importance, train_answer)\n",
    "print(gd.best_score_)\n",
    "print(gd.best_params_)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1200 candidates, totalling 6000 fits\n",
      "0.8484840876278952\n",
      "{'max_depth': None, 'max_features': 0.8, 'min_samples_leaf': 2, 'min_samples_split': 6, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "n_estimators = [10, 50, 100, 200]\n",
    "max_depth = [3, None]\n",
    "max_features = [0.1, 0.2, 0.5, 0.8, 'sqrt', 'log2']\n",
    "min_samples_split = [2, 4, 6, 8, 10]\n",
    "min_samples_leaf = [2, 4, 6, 8, 10]\n",
    "\n",
    "hyperparams = {\n",
    "    'n_estimators': n_estimators, \n",
    "    'max_depth': max_depth, \n",
    "    'max_features': max_features,\n",
    "    'min_samples_split': min_samples_split, \n",
    "    'min_samples_leaf': min_samples_leaf\n",
    "}\n",
    "\n",
    "# GridSearchCV 설정\n",
    "gd = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(random_state=1), \n",
    "    param_grid=hyperparams, \n",
    "    verbose=True, \n",
    "    cv=5, \n",
    "    scoring=\"accuracy\", \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# 202402 업데이트: 최근 라이브러리 버전에서는 fit 에서 정답을 가지고 있는 데이터(train_answer)의 형태로\n",
    "# 1차원 배열 형태를 기대합니다. 따라서, 다음과 같이 1차원 배열로 train_answer 데이터를 변환하기로 합니다.\n",
    "# train_answer를 1차원 배열로 변환\n",
    "train_answer = train_answer.values.ravel()\n",
    "\n",
    "# 모델 훈련\n",
    "gd.fit(train_importance, train_answer)\n",
    "\n",
    "# 결과 출력\n",
    "print(gd.best_score_)\n",
    "print(gd.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1200 candidates, totalling 6000 fits\n",
      "0.8552068294520119\n",
      "{'max_depth': None, 'max_features': 0.5, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "n_estimators = [10, 50, 100, 200]\n",
    "max_depth = [3, None] \n",
    "max_features = [0.1, 0.2, 0.5, 0.8, 'sqrt', 'log2'] # feature 수\n",
    "min_samples_split = [2, 4, 6, 8, 10] # 노드를 분할하기 위한 최소 샘플 수\n",
    "min_samples_leaf = [2, 4, 6, 8, 10] # 리프 노드가 되기 위해 필요한 최소 샘플 수\n",
    "\n",
    "hyperparams = {\n",
    "    'n_estimators': n_estimators, \n",
    "    'max_depth': max_depth, \n",
    "    'max_features': max_features,\n",
    "    'min_samples_split': min_samples_split, \n",
    "    'min_samples_leaf': min_samples_leaf\n",
    "}\n",
    "\n",
    "gd=GridSearchCV(\n",
    "    estimator = ExtraTreesClassifier(random_state=1), \n",
    "    param_grid = hyperparams, \n",
    "    verbose=True, \n",
    "    cv=5, \n",
    "    scoring = \"accuracy\", \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "gd.fit(train_importance, train_answer)\n",
    "print(gd.best_score_)\n",
    "print(gd.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block\" style=\"border: 2px solid #E65100;background-color:#FFF3E0;padding:10px\">\n",
    "<font size=\"4em\" style=\"font-weight:bold;color:#BF360C;\">큰그림으로 이해하기</font><br>\n",
    "<font size=\"4em\" style=\"color:#BF360C;\">훈련 셋을 랜덤하게 분리하므로, 예측 성능은 조금씩 차이는 있을 수 있지만,</font><br>\n",
    "<font size=\"4em\" style=\"color:#BF360C;\">하이퍼파라미터 튜닝 후, 개선된 성능을 확인할 수 있음</font><br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block\" style=\"border: 1px solid #455A64;background-color:#ECEFF1;\">\n",
    "본 자료 및 영상 컨텐츠는 저작권법 제25조 2항에 의해 보호를 받습니다. 본 컨텐츠 및 컨텐츠 일부 문구등을 외부에 공개, 게시하는 것을 금지합니다. 특히 자료에 대해서는 저작권법을 엄격하게 적용하겠습니다.\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
