{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d5900fd",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block\" style=\"border: 2px solid #1976D2;background-color:#E3F2FD;padding:5px;font-size:0.9em;\">\n",
    "본 자료는 저작권법 제25조 2항에 의해 보호를 받습니다. 본 자료를 외부에 공개하지 말아주세요.<br>\n",
    "<b><a href=\"https://school.fun-coding.org/\">잔재미코딩 (https://school.fun-coding.org/)</a> 에서 본 강의를 포함하는 최적화된 로드맵도 확인하실 수 있습니다</b></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5f3309",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 가벼운 딥러닝 적용3 - MULTI-CLASS CLASSIFICATION\n",
    "<div class=\"alert alert-block\" style=\"border: 2px solid #E65100;background-color:#FFF3E0;padding:10px\">\n",
    "<font size=\"4em\" style=\"color:#BF360C;\">지금까지 익힌 이론과 코드만 가지고도, 바로 딥러닝 적용이 가능합니다</font><br>\n",
    "<font size=\"4em\" style=\"color:#BF360C;\">빠르게 여러 문제를 딥러닝에 적용해보며, PYTORCH 와 딥러닝에 우선 익숙해지도록 합니다</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aa11d5d3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris['data']\n",
    "y = iris['target']\n",
    "names = iris['target_names']\n",
    "feature_names = iris['feature_names']\n",
    "\n",
    "# Split the data set into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3ec5f781",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([120, 4]) torch.Size([30, 4]) torch.Size([120]) torch.Size([30])\n"
     ]
    }
   ],
   "source": [
    "std_scaler = StandardScaler()\n",
    "std_scaler.fit(X_train)\n",
    "X_train_tensor = torch.from_numpy(std_scaler.transform(X_train)).float()\n",
    "X_test_tensor = torch.from_numpy(std_scaler.transform(X_test)).float()\n",
    "y_train_tensor = torch.from_numpy(y_train).long()\n",
    "y_test_tensor = torch.from_numpy(y_test).long()\n",
    "\n",
    "print (X_train_tensor.shape, X_test_tensor.shape, y_train_tensor.shape, y_test_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "435346b8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "nb_epochs = 1000 # 1000 epoch 실행 예정\n",
    "minibatch_size = 120 # Mini-batch 사이즈는 256 으로 정하고, 1 epoch 에 10000 개 데이터를 40개의 Mini-batch 로 나누어 40 iteration 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5c482fc6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class FunModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.linear_layers = nn.Sequential (\n",
    "            nn.Linear(input_dim, 100),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(100, 20),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(20, 5),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(5, output_dim),\n",
    "            # nn.Softmax(dim=-1) \n",
    "            nn.LogSoftmax(dim=-1) # 최종 결과는 (5, 3) 이 되므로, dim=-1 로 label 확률값이 들어 있는 마지막 차원을 지정해줘야 함\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = self.linear_layers(x)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a7487c5c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 3\n"
     ]
    }
   ],
   "source": [
    "input_dim = X_train_tensor.size(-1) \n",
    "output_dim = 3 # iris 는 0, 1, 2 Multi-Label 에 대한 확률값을 구해야 하므로, output dimension 은 3 이 되어야 함\n",
    "print (input_dim, output_dim)\n",
    "model = FunModel(input_dim, output_dim)   \n",
    "\n",
    "# loss_func = nn.CrossEntropyLoss() # softmax 는 CrossEntropyLoss() 로 진행해야 함\n",
    "loss_func = nn.NLLLoss() # log softmax 는 NLLLoss() 로 진행해야 함\n",
    "optimizer = torch.optim.Adam(model.parameters()) # Adam, learning rate 필요없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5c799c8a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(1.1004, grad_fn=<DivBackward0>)\n",
      "100 tensor(0.3363, grad_fn=<DivBackward0>)\n",
      "200 tensor(0.0644, grad_fn=<DivBackward0>)\n",
      "300 tensor(0.0417, grad_fn=<DivBackward0>)\n",
      "400 tensor(0.0360, grad_fn=<DivBackward0>)\n",
      "500 tensor(0.0321, grad_fn=<DivBackward0>)\n",
      "600 tensor(0.0274, grad_fn=<DivBackward0>)\n",
      "700 tensor(0.0210, grad_fn=<DivBackward0>)\n",
      "800 tensor(0.0136, grad_fn=<DivBackward0>)\n",
      "900 tensor(0.0078, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for index in range(nb_epochs):\n",
    "    indices = torch.randperm(X_train_tensor.size(0))\n",
    "\n",
    "    x_batch_list = torch.index_select(X_train_tensor, 0, index=indices)\n",
    "    y_batch_list = torch.index_select(y_train_tensor, 0, index=indices)\n",
    "    x_batch_list = x_batch_list.split(minibatch_size, 0)\n",
    "    y_batch_list = y_batch_list.split(minibatch_size, 0)\n",
    "\n",
    "    epoch_loss = list()        \n",
    "    for x_minibatch, y_minibatch in zip(x_batch_list, y_batch_list):\n",
    "        y_minibatch_pred = model(x_minibatch)\n",
    "        loss = loss_func(y_minibatch_pred, y_minibatch)\n",
    "        epoch_loss.append(loss)        \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if (index % 100) == 0:\n",
    "        print (index, sum(epoch_loss) / len(epoch_loss))        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d589cd77",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 테스트셋 기반 Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "02e74abd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_test_pred = model(X_test_tensor)\n",
    "    # torch.argmax(x, dim=차원) # 특정 차원의 데이터 중 가장 높은 값을 가진 index 값을 리턴\n",
    "    y_pred_list = torch.argmax(y_test_pred, dim=1) # 3개의 레이블중 값이 가장 큰 값 (확률) 이 해당 레이블 예측값임 (해당 index 를 최종 결과값으로 활용 가능) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd50462a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### mini-batch size 기반 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "786fcec5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_pred_list = list()\n",
    "x_test_batch_list = X_test_tensor.split(minibatch_size, 0)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for x_minibatch in x_test_batch_list:\n",
    "        y_test_pred = model(x_minibatch)\n",
    "        y_test_pred = torch.argmax(y_test_pred, dim=1)\n",
    "        y_pred_list.extend(y_test_pred.detach().tolist())\n",
    "\n",
    "y_pred_list = torch.tensor(y_pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1ad6e161",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30]) torch.Size([30])\n"
     ]
    }
   ],
   "source": [
    "print (y_pred_list.shape, y_test_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63dcfd13",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Multi-Label Classification 기본 매트릭\n",
    "- None : 라벨 별로 각 계산값 그대로 출력함\n",
    "- micro : 전체 라벨 값을 합하여 계산함\n",
    "- macro : 라벨 별로 계산된 값에 대한 전체 평균을 출력함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f5acff93",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      " [[10  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  0 10]]\n",
      "Precision List:\t [1. 1. 1.]\n",
      "Macro Precision:\t 1.0\n",
      "Macro Precision Formula: 1.0\n",
      "Micro Precision:\t 1.0\n",
      "Recall List:\t [1. 1. 1.]\n",
      "Macro Recall:\t 1.0\n",
      "Micro Recall:\t 1.0\n",
      "Macro F1 Score List:\t [1. 1. 1.]\n",
      "Macro F1 Score:\t 1.0\n",
      "Micro F1 Score:\t 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "\n",
    "print(\"Confusion Matrix\\n\", str(confusion_matrix(y_test_tensor, y_pred_list)))\n",
    "print(\"Precision List:\\t\", str( precision_score(y_test_tensor, y_pred_list, average=None) ) )\n",
    "print(\"Macro Precision:\\t\", str( precision_score(y_test_tensor, y_pred_list, average='macro' ) ) )\n",
    "print (\"Macro Precision Formula:\", str( sum(precision_score(y_test_tensor, y_pred_list, average=None) ) / 3 ))\n",
    "print(\"Micro Precision:\\t\", str( precision_score(y_test_tensor, y_pred_list, average='micro') ) )\n",
    "\n",
    "print(\"Recall List:\\t\", str( precision_score(y_test_tensor, y_pred_list, average=None) ) )\n",
    "print(\"Macro Recall:\\t\", str( recall_score(y_test_tensor, y_pred_list, average='macro') ) )\n",
    "print(\"Micro Recall:\\t\", str( recall_score(y_test_tensor, y_pred_list, average='micro') ) )\n",
    "\n",
    "print(\"Macro F1 Score List:\\t\", str( f1_score(y_test_tensor, y_pred_list, average=None) ) )\n",
    "print(\"Macro F1 Score:\\t\", str( f1_score(y_test_tensor, y_pred_list, average='macro') ) )\n",
    "print(\"Micro F1 Score:\\t\", str( f1_score(y_test_tensor, y_pred_list, average='micro') ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fbb1aa",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block\" style=\"border: 2px solid #1976D2;background-color:#E3F2FD;padding:5px;font-size:0.9em;\">\n",
    "본 자료는 저작권법 제25조 2항에 의해 보호를 받습니다. 본 자료를 외부에 공개하지 말아주세요.<br>\n",
    "<b><a href=\"https://school.fun-coding.org/\">잔재미코딩 (https://school.fun-coding.org/)</a> 에서 본 강의를 포함하는 최적화된 로드맵도 확인하실 수 있습니다</b></div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
