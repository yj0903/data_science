{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block\" style=\"border: 1px solid #455A64;background-color:#ECEFF1;\">\n",
    "본 자료 및 영상 컨텐츠는 저작권법 제25조 2항에 의해 보호를 받습니다. 본 컨텐츠 및 컨텐츠 일부 문구등을 외부에 공개, 게시하는 것을 금지합니다. 특히 자료에 대해서는 저작권법을 엄격하게 적용하겠습니다.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 준비 작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "with open('titanic_step4_importance_train.pickle', 'rb') as pickle_filename:\n",
    "    # 202402 업데이트: pandas 2.0.3 버전 이상에서는 pickle.load 실행시 에러가 남\n",
    "    # 대신에 pd.read_pickle() 호출하면 됨    \n",
    "    # train_importance = pickle.load(pickle_filename)\n",
    "    train_importance = pd.read_pickle(pickle_filename)    \n",
    "with open('titanic_step4_importance_test.pickle', 'rb') as pickle_filename:\n",
    "    # 202402 업데이트: pandas 2.0.3 버전 이상에서는 pickle.load 실행시 에러가 남\n",
    "    # 대신에 pd.read_pickle() 호출하면 됨    \n",
    "    # test_importance = pickle.load(pickle_filename)    \n",
    "    test_importance = pd.read_pickle(pickle_filename)\n",
    "with open('titanic_step4_importance_train_y.pickle', 'rb') as pickle_filename:\n",
    "    # 202402 업데이트: pandas 2.0.3 버전 이상에서는 pickle.load 실행시 에러가 남\n",
    "    # 대신에 pd.read_pickle() 호출하면 됨    \n",
    "    # train_answer = pickle.load(pickle_filename)    \n",
    "    train_answer = pd.read_pickle(pickle_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 주요 라이브러리 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # 각 모델에서 내부적으로 관련 라이브러리 사용 가능\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier             # 1. K-Nearest Neighbor(KNN)\n",
    "from sklearn.linear_model import LogisticRegression            # 2. Logistic Regression\n",
    "from sklearn.svm import SVC                                                # 3. SVC\n",
    "from sklearn.tree import DecisionTreeClassifier                   # 4. Decision Tree\n",
    "from sklearn.ensemble import RandomForestClassifier       # 5. Random Forest\n",
    "from sklearn.ensemble import ExtraTreesClassifier             # 6. Extra Tree\n",
    "from sklearn.ensemble import GradientBoostingClassifier  # 7. GBM\n",
    "from sklearn.naive_bayes import GaussianNB                     # 8. GaussianNB\n",
    "from xgboost import XGBClassifier                                     # 9. XGBoost\n",
    "from lightgbm import LGBMClassifier                                 # 10. LightGBM\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 재트레닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_model = LogisticRegression(C=18.288277344191805, penalty='l2', random_state=1)\n",
    "\n",
    "xgb_model = XGBClassifier(\n",
    "    eval_metric = 'logloss',\n",
    "    learning_rate=0.17, \n",
    "    n_estimators=10, \n",
    "    max_depth=6, \n",
    "    min_child_weight=1,\n",
    "    gamma=0.2,\n",
    "    reg_alpha=0.01,\n",
    "    colsample_bytree=0.85,\n",
    "    subsample=0.9,\n",
    "    random_state=1\n",
    ")\n",
    "\n",
    "random_model = RandomForestClassifier(\n",
    "    max_depth=None, \n",
    "    max_features=0.8, \n",
    "    min_samples_leaf=2, \n",
    "    min_samples_split=6, \n",
    "    n_estimators=200, \n",
    "    random_state=1\n",
    ")\n",
    "\n",
    "extra_model = ExtraTreesClassifier(\n",
    "    max_depth=None, \n",
    "    max_features=0.5, \n",
    "    min_samples_leaf=2, \n",
    "    min_samples_split=10, \n",
    "    n_estimators=50, \n",
    "    random_state=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting Classifier\n",
    "- 일종의 앙상블(ensemble) 의 또다른 기법3 으로(기법1은 Bagging, 기법2는 Boosting), 여러 모델들을 기반으로, 투표를 하는 Voting 기법이 있음\n",
    "- 해당 기법을 사용하여 성능이 괜찮은 모델을 기반으로 Voting 을 해서, 또다른 예측 모델을 구성할 수 있음\n",
    "- Voting 기법도 크게 Hard Voting 기법과 Soft Voting 기법이 존재함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hard Voting Classifier\n",
    "- 여러 모델이 예측한 분류 중, 가장 많은 모델이 예측한 분류를 선택하는 기법\n",
    "\n",
    "<img src=\"https://www.fun-coding.org/00_Images/hardvoting.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84.28849413093967\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "grid_hard = VotingClassifier(estimators = [\n",
    "        ('Logistic Regression', logreg_model),\n",
    "        ('XGBoost', xgb_model),\n",
    "        ('Random Forest', random_model), \n",
    "        ('Extra Trees', extra_model),\n",
    "    ], voting = 'hard')\n",
    "\n",
    "score = cross_val_score(grid_hard, train_importance, train_answer, cv=5, scoring='accuracy')\n",
    "print(np.mean(score)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Soft Voting Classifier\n",
    "- 여러 모델을 확률로 예측 분류한 후, 예측 확률의 평균을 내어, 확률이 가장 높은 분류를 선택하는 기법\n",
    "\n",
    "<img src=\"https://www.fun-coding.org/00_Images/softvoting.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83.95016006528152\n"
     ]
    }
   ],
   "source": [
    "# 튜닝한 파라미터로 소프트보팅\n",
    "grid_soft = VotingClassifier(estimators = [\n",
    "        ('Logistic Regression', logreg_model),\n",
    "        ('XGBoost', xgb_model),\n",
    "        ('Random Forest', random_model), \n",
    "        ('Extra Trees', extra_model),\n",
    "    ], voting = 'soft')\n",
    "\n",
    "score = cross_val_score(grid_soft, train_importance, train_answer, cv=5, scoring='accuracy')\n",
    "print(np.mean(score)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 최종 제출 테스트\n",
    "> 타이타닉 경진대회는 외부에서, 테스트 데이터에 대한 정답셋을 구할 수 있으므로, 정답셋을 가지고 직접 테스트하기로 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('titanic/test.csv')\n",
    "submission = pd.DataFrame(columns=['PassengerId', 'Survived'])\n",
    "submission['PassengerId'] = test['PassengerId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId Survived\n",
       "0          892      NaN\n",
       "1          893      NaN\n",
       "2          894      NaN\n",
       "3          895      NaN\n",
       "4          896      NaN"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingClassifier(estimators=[(&#x27;Logistic Regression&#x27;,\n",
       "                              LogisticRegression(C=18.288277344191805,\n",
       "                                                 random_state=1)),\n",
       "                             (&#x27;XGBoost&#x27;,\n",
       "                              XGBClassifier(base_score=None, booster=None,\n",
       "                                            callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=0.85, device=None,\n",
       "                                            early_stopping_rounds=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            eval_metric=&#x27;logloss&#x27;,\n",
       "                                            feature_types=None, g...\n",
       "                                            monotone_constraints=None,\n",
       "                                            multi_strategy=None,\n",
       "                                            n_estimators=10, n_jobs=None,\n",
       "                                            num_parallel_tree=None,\n",
       "                                            random_state=1, ...)),\n",
       "                             (&#x27;Random Forest&#x27;,\n",
       "                              RandomForestClassifier(max_features=0.8,\n",
       "                                                     min_samples_leaf=2,\n",
       "                                                     min_samples_split=6,\n",
       "                                                     n_estimators=200,\n",
       "                                                     random_state=1)),\n",
       "                             (&#x27;Extra Trees&#x27;,\n",
       "                              ExtraTreesClassifier(max_features=0.5,\n",
       "                                                   min_samples_leaf=2,\n",
       "                                                   min_samples_split=10,\n",
       "                                                   n_estimators=50,\n",
       "                                                   random_state=1))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VotingClassifier</label><div class=\"sk-toggleable__content\"><pre>VotingClassifier(estimators=[(&#x27;Logistic Regression&#x27;,\n",
       "                              LogisticRegression(C=18.288277344191805,\n",
       "                                                 random_state=1)),\n",
       "                             (&#x27;XGBoost&#x27;,\n",
       "                              XGBClassifier(base_score=None, booster=None,\n",
       "                                            callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=0.85, device=None,\n",
       "                                            early_stopping_rounds=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            eval_metric=&#x27;logloss&#x27;,\n",
       "                                            feature_types=None, g...\n",
       "                                            monotone_constraints=None,\n",
       "                                            multi_strategy=None,\n",
       "                                            n_estimators=10, n_jobs=None,\n",
       "                                            num_parallel_tree=None,\n",
       "                                            random_state=1, ...)),\n",
       "                             (&#x27;Random Forest&#x27;,\n",
       "                              RandomForestClassifier(max_features=0.8,\n",
       "                                                     min_samples_leaf=2,\n",
       "                                                     min_samples_split=6,\n",
       "                                                     n_estimators=200,\n",
       "                                                     random_state=1)),\n",
       "                             (&#x27;Extra Trees&#x27;,\n",
       "                              ExtraTreesClassifier(max_features=0.5,\n",
       "                                                   min_samples_leaf=2,\n",
       "                                                   min_samples_split=10,\n",
       "                                                   n_estimators=50,\n",
       "                                                   random_state=1))])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>Logistic Regression</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=18.288277344191805, random_state=1)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>XGBoost</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.85, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, gamma=0.2, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.17, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=6,\n",
       "              max_leaves=None, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=10,\n",
       "              n_jobs=None, num_parallel_tree=None, random_state=1, ...)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>Random Forest</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_features=0.8, min_samples_leaf=2,\n",
       "                       min_samples_split=6, n_estimators=200, random_state=1)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>Extra Trees</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ExtraTreesClassifier</label><div class=\"sk-toggleable__content\"><pre>ExtraTreesClassifier(max_features=0.5, min_samples_leaf=2, min_samples_split=10,\n",
       "                     n_estimators=50, random_state=1)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "VotingClassifier(estimators=[('Logistic Regression',\n",
       "                              LogisticRegression(C=18.288277344191805,\n",
       "                                                 random_state=1)),\n",
       "                             ('XGBoost',\n",
       "                              XGBClassifier(base_score=None, booster=None,\n",
       "                                            callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=0.85, device=None,\n",
       "                                            early_stopping_rounds=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            eval_metric='logloss',\n",
       "                                            feature_types=None, g...\n",
       "                                            monotone_constraints=None,\n",
       "                                            multi_strategy=None,\n",
       "                                            n_estimators=10, n_jobs=None,\n",
       "                                            num_parallel_tree=None,\n",
       "                                            random_state=1, ...)),\n",
       "                             ('Random Forest',\n",
       "                              RandomForestClassifier(max_features=0.8,\n",
       "                                                     min_samples_leaf=2,\n",
       "                                                     min_samples_split=6,\n",
       "                                                     n_estimators=200,\n",
       "                                                     random_state=1)),\n",
       "                             ('Extra Trees',\n",
       "                              ExtraTreesClassifier(max_features=0.5,\n",
       "                                                   min_samples_leaf=2,\n",
       "                                                   min_samples_split=10,\n",
       "                                                   n_estimators=50,\n",
       "                                                   random_state=1))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_hard.fit(train_importance, train_answer)\n",
    "#grid_soft.fit(train_importance, train_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 제출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived\n",
       "0          892         0\n",
       "1          893         0\n",
       "2          894         0\n",
       "3          895         0\n",
       "4          896         1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission[\"Survived\"] = grid_hard.predict(test_importance)\n",
    "submission = submission.astype('int')\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('titanic_predict.csv', header = True, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/davelee/opt_new/anaconda3/bin/kaggle\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "             ^^^^^^\n",
      "  File \"/Users/davelee/opt_new/anaconda3/lib/python3.11/site-packages/kaggle/cli.py\", line 70, in main\n",
      "    out = args.func(**command_args)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/davelee/opt_new/anaconda3/lib/python3.11/site-packages/kaggle/api/kaggle_api_extended.py\", line 801, in competition_submit_cli\n",
      "    submit_result = self.competition_submit(file_name, message,\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/davelee/opt_new/anaconda3/lib/python3.11/site-packages/kaggle/api/kaggle_api_extended.py\", line 748, in competition_submit\n",
      "    url_result = self.process_response(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/davelee/opt_new/anaconda3/lib/python3.11/site-packages/kaggle/api/kaggle_api_extended.py\", line 3565, in process_response\n",
      "    raise Exception(data['message'])\n",
      "Exception: Unauthorized access\n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit -c titanic -f titanic_predict.csv -m \"Test\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block\" style=\"border: 2px solid #E65100;background-color:#FFF3E0;padding:10px\">\n",
    "<font size=\"4em\" style=\"font-weight:bold;color:#BF360C;\">수고 많으셨습니다!</font><br>\n",
    "<font size=\"4em\" style=\"color:#BF360C;\">Kaggle 타이타닉 랭킹: https://www.kaggle.com/c/titanic/leaderboard </font><br><br>  \n",
    "<font size=\"4em\" style=\"color:#BF360C;\">정답셋을 외부에서 찾을 수 있으므로, 스코어가 1 에 가까운 값들은 모두 cheat 라고 봐야 하지만,</font><br>\n",
    "    <font size=\"4em\" style=\"color:#BF360C;\">이러한 경우를 모두 포함하더라도 즉 <b>top 5%</b> 내의 스코어임</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block\" style=\"border: 2px solid #E65100;background-color:#FFF3E0;padding:10px\">\n",
    "<font size=\"4em\" style=\"font-weight:bold;color:#BF360C;\">큰그림으로 이해하기</font><br>\n",
    "<font size=\"4em\" style=\"color:#BF360C;\">데이터 예측 기본 활용을 위해, 다음 단계를 패턴화해서, 활용하기</font><br><br>  \n",
    "<font size=\"4em\" style=\"color:#BF360C;\">1. EDA</font><br>\n",
    "<font size=\"4em\" style=\"color:#BF360C;\">2. Feature Engineering </font><br>    \n",
    "<font size=\"4em\" style=\"color:#BF360C;\">&nbsp;&nbsp;&nbsp;&nbsp;- 숫자 변환 </font><br>    \n",
    "<font size=\"4em\" style=\"color:#BF360C;\">&nbsp;&nbsp;&nbsp;&nbsp;- 도메인 이해 기반 영향력 있는 컬럼 추가 </font><br>       \n",
    "<font size=\"4em\" style=\"color:#BF360C;\">&nbsp;&nbsp;&nbsp;&nbsp;- OneHot Encoding (또는 Label Encoding) </font><br>\n",
    "<font size=\"4em\" style=\"color:#BF360C;\">&nbsp;&nbsp;&nbsp;&nbsp;<b>- 참고(추가 설명): 본 단계에서 스케일링 처리도 할 수 있으며, 이 부분은 이후 강의에서 설명드립니다</b></font><br>\n",
    "<font size=\"4em\" style=\"color:#BF360C;\">&nbsp;&nbsp;&nbsp;&nbsp;- 중요도순 Feature Selection </font><br>                \n",
    "<font size=\"4em\" style=\"color:#BF360C;\">3. Hyper Parameter Tuning (Random Search, Grid Search, Bayesian Optimization)</font><br>    \n",
    "<font size=\"4em\" style=\"color:#BF360C;\">4. VotingClassifier 로 성능이 좋은 모델 기반 추가 모델까지 만든 후</font><br>    \n",
    "<font size=\"4em\" style=\"color:#BF360C;\">5. 최종 훈련 및 예측</font><br>        \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block\" style=\"border: 1px solid #455A64;background-color:#ECEFF1;\">\n",
    "본 자료 및 영상 컨텐츠는 저작권법 제25조 2항에 의해 보호를 받습니다. 본 컨텐츠 및 컨텐츠 일부 문구등을 외부에 공개, 게시하는 것을 금지합니다. 특히 자료에 대해서는 저작권법을 엄격하게 적용하겠습니다.\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
